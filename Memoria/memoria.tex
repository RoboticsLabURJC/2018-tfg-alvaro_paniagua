%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemas y Comunicaciones
%%     Escuela Técnica Superior de Ingenieros de Telecomunicación
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La última versión de esta plantilla está siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las imágenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper, 12pt]{book}
%\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[table,xcdraw]{xcolor}
\usepackage{hyperref} 
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel} % Comenta esta línea si tu memoria es en inglés
\usepackage{url}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{listings}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de índice
\usepackage{latexsym}  %% Logo LaTeX


\title{Memoria del Proyecto}
\author{Álvaro Paniagua Tena}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

\renewcommand{\refname}{Bibliografía}  %% Renombrando
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} 
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
INGENIERÍA EN SISTEMAS AUDIOVISUALES Y MULTIMEDIA

\vspace{0.4cm}

\large
Curso Académico 2018/2019

\vspace{0.8cm}

Trabajo Fin de Grado

\vspace{2.5cm}

\Large
WEBSIM \\
SIMULADOR DE ROBOTS CON TECNOLOGÍAS WEB VR

\vspace{4cm}

\large
Autor : Álvaro Paniagua Tena \\
Tutor : Dr. Jose María Cañas Plaza
\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Para firmar
\clearpage
\pagenumbering{gobble}
\chapter*{}

\vspace{-4cm}
\begin{center}
\LARGE
\textbf{Trabajo Fin de Grado}

\vspace{1cm}
\large
Título del Trabajo con Letras Capitales para Sustantivos y Adjetivos

\vspace{1cm}
\large
\textbf{Autor :} Álvaro Paniagua Tena \\
\textbf{Tutor :} Dr. Jose María Cañas Plaza

\end{center}

\vspace{1cm}
La defensa del presente Proyecto Fin de Carrera se realizó el día \qquad$\;\,$ de \qquad\qquad\qquad\qquad \newline de 20XX, siendo calificada por el siguiente tribunal:


\vspace{0.5cm}
\textbf{Presidente:}

\vspace{1.2cm}
\textbf{Secretario:}

\vspace{1.2cm}
\textbf{Vocal:}


\vspace{1.2cm}
y habiendo obtenido la siguiente calificación:

\vspace{1cm}
\textbf{Calificación:}


\vspace{1cm}
\begin{flushright}
Fuenlabrada, a \qquad$\;\,$ de \qquad\qquad\qquad\qquad de 20XX
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\pagenumbering{Roman} % para comenzar la numeracion de paginas en numeros romanos
\begin{flushright}
\textit{Dedicado a \\
mis padres, familia, y a mi pareja Cristina}
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos

\chapter*{Agradecimientos}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado

En primer lugar dar las gracias a mis padres por apoyarme y animarme 
desde el primer momento. También agradecer a mis compañeros Roberto, 
Ángel y Ahmed por tantas horas de ayuda y clases particulares para que 
entendiese todo bien.

Gracias tambien a Jose María Cañas por darme la oportunidad de 
colaborar en el proyecto.

Por último dar las gracias a mi pareja Cristina, has sido un gran apoyo 
en estos últimos años y sin duda me has motivado a hacer mejor las 
cosas y superarme.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen

\chapter*{Resumen}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
\markboth{RESUMEN}{RESUMEN} % encabezado

El proyecto tiene una intención clara, la creación de un simulador de 
robots aprovechando el crecimiento de las tecnologías web y los nuevos estándares como HTML 5 además
de el crecimiento de la realidad virtual en la web mediante el entorno \textbf{AFRAME}.\\


El proyecto pretende crear una herramienta educativa, \textbf{WebSim}, para la plataforma JdeRobot Kids
y el desarrollo de dos aplicaciones web para resolver ejercicios de \textbf{visión artificial y 
programación de robots} mediante programación en \emph{JavaScript} y mediante el uso de bloques visuales
con \emph{Blockly}. \\

Para el desarrollo del simulador \textbf{WebSim} se han utilizado diversas herramientas.
\begin{itemize}
	\item AFRAME y AFRAME Physics (sistema de físicas de AFRAME).
	\item HTML 5.
	\item JavaScript y jQuery.
	\item CSS3.
	\item Blockly.
	\item ACE Editor.
\end{itemize}

Por último para la gestión de dependencias se utiliza la tecnología NPM.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en inglés

\chapter*{Summary}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el índice
\markboth{SUMMARY}{SUMMARY} % encabezado

This project has a clear intention, create a robot simulator taking advantage of the growth of
web technologies, the new web standard like HTML 5 and the growth of virtual reality on web using
\textbf{AFRAME} framework. \\


The project aims to be an educational tool, \textbf{WebSim}, for the JdeRobot Kids platform and develop
two web applications where students can solve \textbf{artificial vision and robotic programming} 
problems using \emph{JavaScript} or using visual blocks from \emph{Blockly}. \\


Different tools have been used to develop the \textbf{WebSim} simulator.
\begin{itemize}
	\item AFRAME y AFRAME Physics (AFRAME physics system).
	\item HTML 5.
	\item JavaScript y jQuery.
	\item CSS3.
	\item Blockly.
	\item ACE Editor.
\end{itemize}

Finally, NPM technology is used to manage dependencies.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Las buenas noticias es que los índices se generan automáticamente.
% Lo único que tienes que hacer es elegir cuáles quieren que se generen,
% y comentar/descomentar esa instrucción de LaTeX.

%%%% Índice de contenidos
\tableofcontents
%%%% Índice de figuras
\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%%%% Índice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducción}
\label{chap:intro} % etiqueta para poder referenciar luego en el texto con ~\ref{sec:intro}
\pagenumbering{arabic} % para empezar la numeración de página con números

\section{Robótica}
\label{sec:robotica}

La robótica es la rama tecnológica que está involucrada en el diseño, fabricación y la utilización de 
robots. Un robot es una máquina que puede programarse para que interactúe con otros objetos y realice
de manera autónoma tareas costosas para las personas. La robótica combina, entre otras, la informática, 
electrónica, ingeniería y en los últimos años la visión artificial, esta última es muy importante ya 
que la imagen representa un sensor muy potente (contiene mucha información) para el robot.\\


El desarrollo tecnológico ha generado cambios a nivel social facilitándonos a las personas
la mayoría de las tareas que llevamos a cabo a lo largo del día tanto dentro del trabajo
como pueden ser largas cadenas automáticas de fabricación de productos o en el campo
de la medicina con la cirugía como en el ámbito del hogar como es el caso del aspirador Roomba, esto 
ocurre gracias al avance de la rama de la robótica. Este campo tiene como objetivos el simplificar las 
tareas de las personas tanto en la vida cotidiana como en trabajos de alto riesgo mediante el uso de 
autómatas cada vez más desarrollados que sean capaces de realizar tareas más complicadas incluso de 
manera más eficaz a la que la haría un humano.\\

La robótica está presente cada vez en más campos de desarrollo, tenemos aplicaciones que hacen uso de 
la robótica en:

\begin{itemize}
	\item Automoción, el campo de la automoción esta experimentando un fuerte crecimiento en el uso
	de la robótica para el desarrollo de coches autónomos, es decir, coches autotripulados 
	(no necesitan un conductor). Una de las empresas más importantes en este sector es \emph{Waymo}, 
	es una de las empresas de Alphabet (Google) y ya está probando con coches autónomos de 
	nivel 4 que no necesitan un conductor de seguridad. El siguiente enlace muestra un vídeo de cómo
	funcionan estos coches autónomos.
	\url{https://www.youtube.com/watch?v=aaOB-ErYq6Y}
	
	\item Medicina, cabe destacar la existencia del robot llamado Da Vinci (figura ~
	\ref{fig:davinci}) que se ha convertido en uno de los referentes de la cirugía. Se trata de un 
	dispositivo a través del cual se han conseguido llevar a cabo con éxito operaciones tan importantes 
	como las de cirugía transoral, esta cirugía se basa en el uso de un brazo robótico que puede 
	manejar el cirujano para la extracción de cáncer en partes de la boca y garganta de acceso difícil.

	\begin{figure}[h]
		\centering
		\includegraphics[width=9cm, height=7cm]{img/davinci.jpg}
		\caption{Imagen del robot \emph{Da Vinci} usado en operaciones quirúrgicas.}
		\label{fig:davinci}
	\end{figure}	
	
	
	\item Centros logísticos, este campo se encuentra en desarrollo, una de las empresas que más se 
	importancia adopta en este ámbito es Amazon con el uso de \emph{Drones} para la entrega de 
	artículos y sus robots \emph{Drives} que usan de manera interna para acelerar las entregas en sus 
	centros logísticos. Estos robots lo que hacen es deslizarse debajo de grandes estanterías donde se 
	encuentran los artículos y las llevan hacia los operarios o el destino indicado al robot. España es 
	actualmente	el tercer país en adoptar esta tecnología de la empresa Amazon en los centros 
	logísticos. En la siguiente figura se muestra los robots utilizados por la empresa Amazon.
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=12cm, height=6cm]{img/amazonrobot.jpg}
		\caption{Imagen del robot utilizado en los centros logísticos de Amazon para acelerar el 
		proceso de entrega de productos.}
		\label{fig:amazon}
	\end{figure}
	
\end{itemize}


Actualmente la industria de la robótica está experimentando un gran crecimiento entrando en un mayor
número de campos tecnológicos, se prevé un aumento de la demanda de profesionales en el campo de la
robótica debido a esta diversidad y a la mayor sofisticación de los robots. Un ejemplo del grado de
avance que tienen actualmente los robots se puede ver en el vídeo a continuación que presenta los
prototipos de la empresa \emph{Boston Dynamics} en el que se puede apreciar que cada vez los robots
tienen funcionalidades más complejas (minuto 9 en el vídeo).\\

\url{https://www.youtube.com/watch?v=KEMt58ePNDs}


\newpage
\section{Robótica educativa}
\label{sec:robotica-educativa}

La robótica educativa ofrece entornos de aprendizaje basados en la actividad de los estudiantes, es 
decir, aprender el pensamiento lógico que va más allá de la programación o el diseño de robots mediante 
el uso de entornos 'simplificados' para el alumno. Además fomenta la resolución de problemas y el 
trabajo en equipo a través de recursos tecnológicos. La robótica es un campo multidisciplinar 
que conjunta el conocimiento matemático, físico y tecnológico por lo tanto es un campo que conjuga
muy bien con las actuales materias educativas a la vez de ser una materia de aplicación, es decir,
los alumnos pueden ver el resultado de la aplicación de estos conocimientos en el robot.\\

Muchos proyectos han demostrado que el uso de kits de robótica para el aprendizaje de los alumnos
aumenta la capacidad de reflexión de estos, Jhon Siraj-Blatchford, profesor de la universidad de
Cambridge, en el libro \emph{Nuevas tecnologías para la educación infantil y primaria} argumenta este
tema. Además se ofrece un entorno educativo distinto al tradicional, más adaptado al mundo actual 
donde la tecnología crece a gran velocidad y donde los alumnos pueden conocer una motivación por un
entorno al que no tendrían acceso hasta unos estudios superiores o especializados. La figura 
~\ref{fig:lego} muestra un kit de robótica educativa en el que se ofrecen piezas para
la construcción de una serie robots simples y la herramienta para programar su funcionalidad.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=10cm, height=6cm]{img/lego-wedo-2.jpg}
	\caption{Kit \emph{Lego WeDo 2} para robótica educativa.}
	\label{fig:lego}
\end{figure}

Además como se ha mencionado anteriormente, cada vez el desarrollo y sofisticación de estos autómatas
es mayor debido a que se intenta que tengan una funcionalidad similar a la de un humano dotándolos 
incluso de \emph{inteligencia artificial} por tanto es necesario profesionales cada vez mejor formados
lo que conlleva la necesidad de formación en esta rama desde edades más tempranas.\\

En el siguiente enlace se muestra un vídeo en el cual se hablan de las posibles aplicaciones de la 
robótica en la educación, en la charla se expone cómo aprenden los niños con la robótica los problemas
de la contaminación lumínica para los animales.\\

\url{https://www.youtube.com/watch?v=FDnhMTxhddM}

\newpage
\section{Tecnologías Web}
\label{sec:tec-web}



Una de las ventajas principales que ofrecen las
tecnologías web es la ausencia de necesidad de instalación de paquetes
de software, configuración y dependencias. Basta con tener un navegador
y una conexión a internet, todos los archivos necesarios para la ejecución 
de la aplicación se sirven de manera automática al ingresar la URL dentro de la barra de navegación.

El cliente no tiene la necesidad de instalar actualizaciones 
ya que únicamente se actualiza la versión que proporciona el servidor,
esto elimina las incompatibilidades entre versiones ya que todos los
clientes usarán la misma versión.
Desarrollo unificado, con esto hacemos referencia a que no se necesita
desarrollar para los distintos sistemas operativos (Windows, MacOS,
Linux/Ubuntu, etc.) así como conocer sus entornos gráficos y 
dependencias del sistema operativo, lo único necesario es saber HTML5, 
JavaScript y CSS3 , el navegador se encarga de interpretar los
distintos lenguajes.\\

No todo son ventajas, como desventaja sabemos que las aplicaciones 
web son algo más lentas debido a la necesidad de descargar los recursos
y no ser lenguajes compilados como C++ o Java sino interpretados, ésta 
desventaja cada vez va siendo menor debido a las mejoras en los interpretes de JavaScript en los
navegadores y protocolos como por ejemplo \emph{AJAX (Asynchronous 
JavaScript and XML requests} que trata de una técnica de peticiones 
ligeras para aplicaciones interactivas.

Además con los años ha aumentado el número de navegadores distintos y
desarrollar la aplicación para todos ellos es costoso aunque existen
entornos que facilitan esta tarea como pueden ser Express y Loopback
para el lenguaje JavaScript y Django para el lenguaje Python.\\

El uso de las tecnologías web ha aumentado debido al lanzamiento del nuevo estándar HTML 5 en el que
tenemos características muy importantes para la transmisión de contenido multimedia con la inserción
de la etiqueta \emph{video y canvas} en las que podemos incluír vídeos y generar escenas 2D y 3D 
respectivamente. A continuación se enumeran y explican algunas de las características más destacables
del nuevo estándar HTML 5.

\begin{itemize}
	\item Aceleración gráfica con WebGL y la etiqueta \emph{canvas}, esto permite el uso de aceleración
	gráfica hardware basada en OpenGL evitando el uso de \emph{plugins} (extensiones) y generando estos
	gráficos a partir de código JavaScript. Los elementos WebGL se pueden mezclar con otros elementos
	HTML y componerse con otras partes de la página o el fondo de la misma.
	
	\item WebWorkers, el nuevo estándar HTML 5 ofrece un API para generar ejecuciones de código en
	segundo plano en paralelo con el programa principal, esto permite operaciones por hilos de 
	ejecución con un mecanismo de mensajes entre hilos para el control de ejecución.
	
	\item WebStorage, este API es la evolución del mecanismo de las cookies para mantenimiento de 
	estado en el protocolo HTTP el cual sabemos que es sin estado. El tipo de almacenamiento es similar
	al de las cookies, se usa el par clave-valor. La principal diferencia entre el ambos mecanismos es
	que WebStorage ofrece mayor capacidad para guardar datos en el navegador y una mejor seguridad.
	
	\item WebSockets, este API permite abrir un canal de comunicación bidireccional con un servidor 
	o con una aplicación de terceros. El tipo de comunicación usada es mediante eventos, ambas partes
	de la comunicación deben hacer uso del mismo tipo de mensajes. Los mensajes los define el 
	desarrollador de la aplicación. El protocolo de apertura de WebSockets consiste en el protocolo
	\emph{handshake} en el cual ambas partes de la comunicación se ponen de acuerdo en el canal a usar
	y entonces se inicia la transmisión de mensajes sobre TCP. Como características destacar que al
	ir sobre el protocolo TCP se ofrece redundancia, es decir, si el mensaje se pierde se vuelve a 
	enviar ofreciendo la fiabilidad de que el mensaje llegará al destino y además son transmisiones 
	de baja latencia.
	
	\item ServerSent Events, define un API para la apertura de una conexión HTTP en la cual el servidor 
	puede enviar notificaciones al cliente, dotando de capacidad de iniciativa de envío de mensajes
	del lado servidor. Previo a HTML 5 esto no era posible, el servidor tenía que esperar una petición
	del cliente para responder.
	
	\item WebRTC, define un API de transmisión y recepción de contenido multimedia desde otro navegador
	o dispositivo que implemente lo protocolos de transmisión en tiempo real. Lo más importante de esta
	API es que abstrae al desarrollador de toda la problemática que trae consigo el envío de audio y 
	vídeo como son el retardo, el jitter, el uso del mismo formato de transmisión, etc. El jitter
	es un problema muy importante en transmisión de audio y vídeo y es la variación del retardo 
	de la transmisión debido a la fluctuación de la red. Una aplicación que hace uso de este API es 
	\url{www.appear.in} que es un servicio de videollamada similar a Skype pero en Web.
	
	 
\end{itemize}

Existen muchísimos entornos para el desarrollo web y cada uno de ellos tiene una funcionalidad 
específica que lo hace importante por lo tanto se hace complicado marcar un único entorno como
el mejor. Debido a esta problemática el desarrollador ha de buscar el entorno que mejor se ajuste
a la aplicación ha desarrollar. Una tendencia actual en el desarrollo web a nivel profesional es 
el desarrollo de API Rest (Transferencia de Estado Representacional) y se basa en:

\begin{itemize}
	\item  Desacoplación del cliente y el servidor, es decir, el cliente no se preocupa de la 
	implementación del servidor y el servidor se despreocupa de cómo van a ser usados sus datos.
	
	\item Sin estado, es decir, cada petición es independiente y no existen las sesiones.
	
	\item Interfaz uniforme, define una interfaz genérica de acceso a los datos lo cual permite el 
	desacople entre el lado cliente y el lado servidor.
	
	\item Sistema de capas, el servidor puede disponer de varias capas para su implementación. 
	Esto ayuda a mejorar la escalabilidad, el rendimiento y la seguridad.
\end{itemize}

Debido a esta tendencia en el desarrollo web cabe mencionar un conjunto de entornos que hacen que 
el desarrollo de aplicaciones API Rest se simplifique en gran medida. Sigue las siglas \emph{MEAN}
(MongoDB - Express - AngularJS - NodeJS) aunque ha evolucionado en los últimos años a MLRN 
(MongoDB - Loopback - React - NodeJS). Todos estos frameworks tienen una característica en común 
y es que todos se escriben en el lenguaje JavaScript. A continuación se explican brevemente cada uno
de ellos.

\begin{itemize}
	\item MongoDB, es un sistema de base de datos no relacional (NoSQL) que no usa el sistema de tablas
	sino que guarda los registros de manera similar a un JSON con un esquema dinámico.
	
	\item Loopback, es la extensión del entorno Express, ambos montados sobre NodeJS. Loopback ofrece
	una configuración predefinida para generar API Rests y ofrece los métodos básicos (CRUD, 
	Create-Read-Update-Delete) para cada uno de los puntos de acceso del API Rest. Además ofrece
	conectores con la mayoría de bases de datos incluso ofrece almacenamiento en memoria para su uso
	en desarrollo.
	
	\item React, entorno web de lado cliente que permite simplificar la creación de interfaces de 
	usuario interactivas mediante el lenguaje JavaScript. Se basa en un sistema de componentes que son
	partes de código aisladas con una funcionalidad específica.
	
	\item NodeJS, tecnología de desarrollo del lado servidor en lenguaje JavaScript, permite la 
	creación de servidores web de manera rápida. Es un entorno diseñado para soportar una gran cantidad 
	de peticiones por segundo. Implementa un hilo de peticiones y multihebras, cada vez que una
	petición llega es enrutada a una hebra por el hilo de peticiones, una vez acabado el procesado
	de la petición se lanza un evento desde la hebra y se recoge en el hilo de ejecución devolviendo
	la respuesta.
\end{itemize}


Como conclusión, las tecnologías web están avanzando cada vez más 
con el objetivo de llegar al rendimiento de las aplicaciones de 
escritorio hasta el punto de existir entorno para el desarrollo de
aplicaciones híbridas, es decir, desarrolladas con lenguaje web pero 
haciendo uso del sistema operativo como es el caso de \emph{Electron}.


\newpage
\section{Motivación}
\label{sec:motivacion}

La motivación de este proyecto es la de sustituir el presente simulador \emph{Gazebo} por
WebSim, un simulador desarrollado íntegramente con tecnologías Web con peso computacional
en el lado cliente lo que permite escalar el número de usuarios que lo utilizan de manera
simultánea.



\section{Estructura de la memoria}
\label{sec:estructura}

En esta sección se detalla la estructura de la memoria que constará de las siguientes partes:

\begin{itemize}
  \item El capítulo~\ref{chap:intro} es una introducción al campo en el que se desarrolla el proyecto,
  se explica la motivación del proyecto y la motivación personal.

  \item En el capítulo~\ref{chap:objetivos} se muestran los objetivos a 
  completar para la elaboración del proyecto y la estructura de la hoja de ruta.

  \item En el capítulo~\ref{chap:herramientas} se presentan las 
  tecnólogias que se han utilizado para el desarrollo del proyecto y se 
  explica el porqué de dichas tecnologías y no otras.

  \item En el capítulo~\ref{chap:disenno} se explicarán el diseño de la 
  aplicación, soporte del robot, es decir, qué funcionalidades tiene y 
  la conectividad que dispone el simulador.
  
  \item En el capítulo~\ref{chap:usos} se muestran ejercicios que el alumno podrá resolver
  usando el lenguaje \emph{JavaScript} y haciendo uso del lenguaje de bloques visuales \emph{Blockly}.
  
  \item Finalmente en el capítulo~\ref{chap:conclusiones} se hace una 
  valoración de todo lo que ha conllevado el proyecto y se proponen 
  futuras implementaciones o mejoras de WebSim.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% OBJETIVOS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage % empezamos en página impar
\chapter{Objetivos} % título del capítulo (se muestra)
\label{chap:objetivos} % identificador del capítulo (no se muestra, es para poder referenciarlo)

\section{Objetivo general} % título de sección (se muestra)
\label{sec:objetivo_general} % identificador de sección (no se muestra, es para poder referenciarla)

Mi trabajo fin de grado consiste en crear la base de una herramienta educativa para 
simulación de robots para la plataforma JdeRobot Kids en la cual el peso computacional la 
lleve el lado cliente en lugar del lado servidor.


\section{Objetivos específicos}
\label{sec:objetivos_especificos}

El objetivo específico de el proyecto es la simulación del robot 
\textbf{PiBot} implementando así todo su conjunto de sensores y 
actuadores en los que se encuentran:

\begin{itemize}
	\item \textbf{Motores}: son dos servomotores independientes que 
	dotan de movimiento al robot.
	
	\item \textbf{Cámara}: una minicámara, ésto le da funcionalidad muy 
	importante al robot como puede ser la detección de obstáculos.
	
	\item \textbf{Sensores IR}: dos sensores infrarrojos posicionados 
	en la parte baja del chasis del robot, estos sensores permiten la 
	detección de colores, objetos y formas.
	
	\item \textbf{Sensor de ultrasonidos}: Dos sensores de ultrasonido 
	posicionados en la parte delantera del chasis del robot, su 
	funcionalidad es la de sensores de proximidad lo que permite saber 
	no solo si hay un objeto delante sino que también permite saber
	a qué distancia está dicho objeto.
	
\end{itemize}


\section{Planificación}
\label{sec:planificacion}

\subsection{Metodología}
\label{subsec:metodologia}

Para el desarrollo del proyecto se ha seguido la metodología \textbf{Agile}, es una forma de realizar
los proyectos en la cual el proyecto al completo se parte en partes más pequeñas que se desarrollan 
en un par de semanas. De modo que el cliente puede ir haciendo pequeños cambios al proyecto en función
de la ventaja de mercado que quiera obtener y le permite ir viendo el desarrollo del proyecto en
intervalos de tiempo reducidos. Estos intervalos de tiempo se llaman \emph{sprints} en el cual el 
desarrollador se centra únicamente en programar el software y si el \emph{sprint} lo permite se 
genera documentación de lo hecho en el \emph{sprint}.\\

Para la simulación de esta metodología se han hecho reuniones semanales con los tutores del TFG en el
cual se les presentaba un prototipo y se proponían cambios, mejoras y desarrollos a llevar a cabo
en la próxima semana. Por norma los \emph{sprints} se sobredimensionaban, es decir, se proponían 
desarrollos que no iban a entrar en la planificación temporal, ésto se ha hecho así para mantener
la idea general del proyecto y no desviarnos de esta idea y además poder evitar el problema de no 
desarrollar nada si lo fijado en la reunión ya se había completado.

\subsection{Planificación temporal}
\label{subsec:planificacion_temporal}

A continuación se muestran tres imágenes que representan la 
planificación temporal 

\begin{figure}

  \includegraphics[width=\linewidth]{img/GANTT-1.PNG}
  \caption{Diagrama de GANTT para el rango de fechas 14 de Julio de 
  2018 al 1 de Septiembre de 2018.}
  \vspace{1.5cm}
  
  \includegraphics[width=\linewidth]{img/GANTT-2.PNG}
  \caption{Diagrama de GANTT para el rango de fechas 2 de Septiembre de 
  2018 al 21 de Octubre de 2018.}
  \vspace{1.5cm}
  
  \includegraphics[width=\linewidth]{img/GANTT-3.PNG}
  \caption{Diagrama de GANTT para el rango de fechas 22 de Octubre de 
  2018 al 28 de Octubre de 2018.}
  
  \label{fig:gantt}
  
\end{figure}

El nivel de esfuerzo para este proyecto ha sido alto debido a la 
necesidad de aprender diferentes tecnologías como son AFRAME, jQuery y
OpenCVjs. Se dedicaban alrededor de 3-4 horas al día cada día de la 
semana a excepción de los fines de semana que se añadían 2 horas más 
al anterior intervalo.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ESTADO DEL ARTE (FRAMEWORKS) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Herramientas}
\label{chap:herramientas}


\section{JavaScript}
\label{sec:javascript}

\textbf{\emph{JavaScript}} fue creado por Brendan Eich en 1995 cuando
trabajaba para Netscape Communications inspirado por el lenguaje Java. Se encuentra 
actualmente bajo el estándar \emph{ES6 (ECMAScript 6 o ECMAScript 2015} que añade ciertas
características al lenguaje que se explicarán más adelante.

Es el lenguaje más utilizado para el desarrollo Web, permite que las aplicaciones web 
sean interactivas, es decir, permite hacer actualizaciones de contenido en el momento, 
mostrar mapas, animaciones 3D. Es el tercer pilar del estándar de tecnologías web 
compuesto por \textbf{\emph{HTML, CSS y JS}}.

\subsection{Características de JavaScript}
\label{subsec:JS-features}

\emph{\textbf{JavaScript}} es un lenguaje de \emph{scripting} orientado al lado cliente de una
aplicación como ya se ha comentado anteriormente, y cuenta con las siguientes características:

\begin{itemize}
	\item Lenguaje de \textbf{alto nivel}, esto quiere decir que su 
	sintaxis es similar a la escritura habitual de una persona, por 
	ejemplo:
	\begin{lstlisting}
	function myFunction(){
		console.log("Hello world");	
	}
	\end{lstlisting}
	
	\item Lenguaje basado en \textbf{objetos}, esto es una estructura
	habitual en programación que se refiere a la encapsulación de 
	operaciones y estados en un modelo de datos. Otros lenguajes 
	orientados a objetos serían \emph{Python, Ruby, Java, etc.} La
	figura ~\ref{fig:objeto-javascript} representa de manera visual la orientación a 
	objetos.
	\begin{figure}[h]
		\centering
		\includegraphics[width=6cm, height=3.5cm]
		{img/objects_and_classes.png}
		
		\caption{En la parte izquierda de la imagen se muestra el 
		objeto \textbf{coche} del que heredan los 3 de la parte
		derecha de la imagen, los 3 coches tienen en común que son
		del objeto coche pero se diferencian en \textbf{marca} y
		\textbf{color.}}
		
		\label{fig:objeto-javascript}
	\end{figure}
	
	\item Tipado débil, esto quiere decir que no es necesario declarar el tipo de una variable, 
	una variable cualquiera puede ser de distintos tipos en momentos distintos pasando de un 
	\emph{string} a un \emph{number} o a un \emph{objeto}. En la figura ~\ref{fig:js-code} se 
	muestra un ejemplo de esta característica en el que la variable \textbf{msg} es declarada
	inicialmente con contenido de tipo \emph{string} y posteriormente se modifica su contenido para
	que sea de tipo \emph{number}.
	\begin{figure}[h]
		\centering
		\includegraphics[width=13cm, height=3.5cm]
		{img/js-vars.png}
		
		\caption{En la parte izquierda de la imagen se muestra el 
		código que imprime la variable \textbf{msg} tras modificar su tipo}
		
		\label{fig:js-code}
	\end{figure}
	
	\item Es un lenguaje \emph{case-sensitive}, es decir, distingue las letras mayúsculas de las 
	minúsculas, a la hora de declarar una variable o función no es lo mismo \emph{miVariable} que
	\emph{mivariable}. La manera correcta para definir nombres de variables o funciones en este lenguaje
	es seguir la sintaxis \emph{camel-case} en la cual si el nombre de mi variable está compuesta por
	varias palabras la primera de ellas estará completamente en minúsculas y las palabras que la siguen
	tendrán la primera letra en mayúsculas, a continuación se muestra un ejemplo: 
	\emph{miVariableDeMuestra}.
	
	\item Al igual que otros lenguajes como \emph{Python}, \emph{JavaScript} es un lenguaje 
	\textbf{interpretado} esto quiere decir que no se necesita un compilador para crear un binario del
	código sino que existe un interprete dentro del navegador que se encarga de ejecutarlo.
\end{itemize}


Como hemos comentado en la introducción de \emph{JavaScript} éste se encuentra bajo el estándar
\emph{ES6} lo cual le dota de una serie de características importantes, a continuación se citarán
algunas de las características que son más relevantes para el proyecto:

\begin{itemize}
	\item Definición de variables con ámbito local \emph{(Block-Scoped Variables)}, esta característica
	permite declarar una variable que únicamente existirá en un determinado bloque y no fuera de éste,
	mejora la inteligibilidad del código a la hora de que lo tengan que leer distintos 
	desarrolladores de un equipo. Esta característica existía anteriormente pero el desarrollador 
	debía tener conocimiento del \emph{scoping} de variables, es decir, cuando una variable afectaba 
	a un bloque y cuándo no. En la figura ~\ref{fig:let-scope} se muestra un uso de este tipo
	de declaración, la variable \textbf{x} únicamente existe dentro del bucle \emph{for}.
	\begin{figure}[h]
		\centering
		\includegraphics[width=7cm, height=1.7cm]
		{img/let-scope.png}
		
		\caption{Ejemplo de la declaración de variables locales con la etiqueta \emph{let}.}
		
		\label{fig:let-scope}
	\end{figure}
	
	\item Funciones de flecha, en el estándar ES6 se permite la declaración de funciones sin la creación
	de un contexto \emph{this}, este contexto hace referencia al bloque en el que se encuentra.
	Anteriormente a ES6 si se necesitaba usar el contexto de otra función en un determinado bloque
	había que hacer la siguiente transformación \emph{var self = this;} lo que permitía usar el 
	contexto dentro de una nueva función llamando a \emph{self}, gracias a ES6 esto ha cambiado, la 
	figura ~\ref{fig:arrow-func} muestra un ejemplo de la nueva sintaxis.
	\begin{figure}[h]
		\centering
		\includegraphics[width=6cm, height=1.7cm]
		{img/arrow-func.png}
		
		\caption{El contexto \emph{this} es siempre el mismo gracias a la declaración de la función
		de flecha.}
		
		\label{fig:arrow-func}
	\end{figure}
	
	\item Exportar e importar módulos, esta característica es similar a los import de \emph{Python} lo
	que dota de mucha modularidad a la aplicación ya que permite tener un programa principal que 
	controla el uso de las distintas funcionalidades evitando así las aplicaciones monolíticas y permite
	que cada nueva funcionalidad sea completamente independiente de las demás lo que hace que la 
	modificación de esta funcionalidad no afecte a las demás. La figura ~\ref{fig:js-export} muestra
	la sintaxis para exportar una variable y una función para ser utilizada en distintos scripts.
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=11.5cm, height=5.5cm]
		{img/js-exports.png}
		
		\caption{La figura muestra la sintaxis para importar o exportar funciones entre distintos 
		programas dentro de una aplicación o entre varias lo que permite reutilizar mismo código entre
		distintas aplicaciones.}
		
		\label{fig:js-export}
	\end{figure}	
	
	\item Declaración de clases, es una modificación que permite mejorar la inteligibilidad del código
	ya que esta característica se permitía en anteriores estándares pero con una sintaxis distinta
	que podría dar lugar a confusiones a la hora de entender el código. La figura ~\ref{fig:class-def}
	muestra una comparativa entre ambas sintaxis, en la parte superior vemos la sintaxis en estándares
	y en la parte inferior la sintaxis de ES6.
	
	\begin{figure}[h]
  		\centering
  		\begin{minipage}[b]{0.4\textwidth}
    		\includegraphics[width=\textwidth]{img/class-prev.png}
    		\caption{Estándares previos a ES6.}
  		\end{minipage}
  		\hfill
  		\begin{minipage}[b]{0.4\textwidth}
    		\includegraphics[width=\textwidth]{img/class-es6.png}
    		\caption{Estándar ES6.}
  		\end{minipage}
  		\label{fig:class-def}
\end{figure}

\end{itemize}

\subsection{Entornos JavaScript}
\label{subsec:js-frameworks}

Este lenguaje tiene mucho peso en el lado cliente, es decir, en el código que se 
ejecuta en el navegador pero gracias a la entrada de NodeJS cuando éste lenguaje ha 
obtenido más peso dentro del desarrollo web ya que NodeJS permite la creación de
servidores de manera sencilla.

Actualmente \textbf{JavaScript} se utiliza en multitud de entornos tanto de lado 
cliente como en el lado servidor, a continuación se enumeran algunos de los más usados:

\begin{itemize}
	\item \textbf{NodeJS}: Tecnología en el lado servidor con código completamente 
	JavaScript asíncrono y orientado a eventos, NodeJS fué diseñado para construir 
	aplicaciones en red escalables. Su principal característica es la capacidad de 
	gestionar multitud de conexiones simultáneas de una manera muy eficaz gracias a su
	arquitectura. Se basa en un hilo que escucha peticiones y las redirecciona a 
	\textbf{hebras} distintas, cada una de estas hebras ejecuta el código necesario y
	una vez la hebra termina lanza un evento al hilo de peticiones indicando que ha 
	terminado de ejecutar la tarea indicada entonces es el hilo de peticiones el que se
	encarga de devolver la respuesta.
	
	\item \textbf{Express y Loopback}: Ambos entornos son extensiones de NodeJS y 
	permiten la creación de un API en el lado servidor. Loopback es actualmente más 
	importante que Express ya que ofrece muchas herramientas para la creación de
	API Rest de manera muy sencilla así como conectores a la mayoría de bases de datos
	como puede ser MongoDB, mySQL, sqlite3, etc.
	
	\item \textbf{AngularJS} Es un entorno basado en el \emph{Modelo Vista Controlador}
	para el desarrollo en la parte cliente que permite la creación de aplicaciones web
	\textbf{SPA} (\emph{Simple-Page-Application}). AngularJS permite extender el 
	lenguaje HTML con directivas y atributos sin perder la semántica.
	
	\item \textbf{AFRAME} Es un entorno de creación de escenas de 
	\emph{Realidad Virtual}, se hablará de manera más extensa en el apartado ~
	\ref{sec:aframe}. No es un entorno muy extendido debido a su juventud pero
	cuenta con una gran comunidad de desarrolladores y es el pilar central 
	del proyecto que se lleva a cabo.
\end{itemize}

Esta imagen creada de los entornos disponibles para JavaScript sirve como 
respaldo ante la decisión de elegir el lenguaje. Además como se ha comentado en la 
subsección ~\ref{subsec:motivacion} el proyecto se orienta a la creación de una 
aplicación con peso en el lado cliente, por tanto sabiendo ésto y teniendo en cuenta que
AFRAME está creado en el lenguaje JavaScript la elección de este lenguaje gana peso por
sí sola.

\newpage
\section{HTML}
\label{sec:html}

\textbf{\emph{HTML}} fue creado por \emph{Tim Berners-Lee} en 1990 y es el acrónimo para
\emph{HyperText Markup Language} (Lenguaje de marcas de hipertexto). 

Se utiliza para la creación de documentos electrónicos que se envían a través de la red
global (internet). Cada documento tiene una serie de conexiones a otros documentos 
llamados \textbf{\emph{hyperlinks}} que permiten la navegación entre distintos recursos.

\textbf{HTML} asegura el formato correcto de texto, imágenes y estilos para poder leer
un documento con el navegador con la forma original con la que se generó el documento. En
la figura ~\ref{fig:estructura-html} se muestra una página HTML muy simple y se explican 
sus distintas partes y su función.

\begin{figure}[h]
	\centering
	\includegraphics[width=9.5cm, height=4.5cm]{img/html-ejemplo.png}
	\caption{Estructura de una pagina HTML simple con un título y un párrafo}
	
	\label{fig:estructura-html}
\end{figure}

Como vemos en la figura anterior,un documento HTML tiene una estructura de árbol donde
la etiqueta \textbf{html} es el elemento raíz y cada nuevo elemento es una rama del anterior. 

Como elementos principales del documento HTML tenemos la declaración documento
\textbf{DOCTYPE html} que en este caso indica que estamos ante un documento
HTML 5 que es última versión de HTML. Como hemos indicado en el párrafo anterior la 
etiqueta \textbf{html} marca la raíz del documento, dentro de ésta etiqueta tenemos dos 
etiquetas importantes:

\begin{itemize}
	\item \textbf{HEAD} es la cabecera del documento, contiene los metadatos del documento
	como el título, la codificación de caracteres utilizada y links a otros recursos 
	adicionales como pueden ser \emph{scripts} y \emph{hojas de estilos}.
	
	\item \textbf{BODY} es el contenido que se mostrará del documento, puede contener
	imágenes, enlaces a otros documentos, vídeos, menús de navegación, formularios, 
	botones e incluso escenas animadas como la que se mostrará en el presente proyecto.
\end{itemize}

Las combinaciones de elementos son muy amplias, no existe una única estructura válida para
un documento HTML sino que se genera una estructura en función de la aplicación.

Dentro del estándar HTML se ha escogido el estándar HTML5, a continuación se enumeran 
las nuevas características de éste nuevo estándar que tienen relación con el proyecto:

\begin{itemize}
	\item \textbf{VIDEO}, esta etiqueta es una de las nuevas características
	de HTML5 y una de las más importantes, permite embeber vídeos dentro de una página 
	web de manera nativa sin el uso de \emph{plugins}.
	
	\item \textbf{NAV}, esta etiqueta declara un elemento de tipo \emph{barra de
	navegación} en el cual se encuentra el menú con enlaces a otros tipos de recursos
	y secciones tanto dentro como fuera de la página. En nuestro caso esta etiqueta se ha
	utilizado para encapsular los botones de arranque/pare del código creado por el alumno
	y el botón que permite mostrar u ocultar la cámara del robot.
	
	\item \textbf{CANVAS}, permite la renderización de escenas gráficas a través de 
	JavaScript. Es la etiqueta más importante dentro de nuestro proyecto ya que es la
	etiqueta que nos permite la creación de la escena en la cual tenemos nuestro 
	robot simulado.
\end{itemize}

Existe una característica importante que afecta a todo el documento de HTML5 pero que,
en general, no se está respetando en el desarrollo web y es que HTML5 tiene una tendencia
semántica, es decir, las etiquetas como \textbf{SECTION, NAV y FOOTER} marcan claramente
zonas dentro del documento HTML con el fin de poder conocer la estructura del documento
de manera clara.


\newpage
\section{CSS}
\label{sec:css}

\textbf{\emph{CSS}} o \emph{Cascading StyleSheet} es un lenguaje que se usa para definir
el aspecto visual de una página HTML. Su principal misión es la de separar la estructura
y contenido del aspecto de la pagina HTML.\\

Con \textbf{CSS} podemos controlar incluso cómo se van a ver todos los documentos HTML de
mi aplicación, es comúnmente utilizado por las empresas y diseñadores gráficos para crear
de manera visual una identificación de la aplicación mediante tipos de letra, paleta de
colores utilizada.

Deja atrás la gran necesidad de uso de JavaScript para fines de representación visual lo 
que hace que el rendimiento de la página se mejore al usar código JavaScript para otros 
fines. Además reduce la dependencia de software de edición gráfica como \emph{Photoshop},
que sigue siendo utilizado pero su función es la edición más avanzada.

A continuación se muestra una imagen con una comparativa de la misma página web con y 
sin CSS.

\begin{figure}[h]
	\centering
	\includegraphics[width=9cm, height=7cm]{img/css-comparacion.png}
	\caption{Imagen comparativa de la misma pagina web con y sin hojas CSS}
	
	\label{fig:css}
\end{figure}

Como vemos en la figura ~\ref{fig:css} las hojas de estilo CSS permite modificar
completamente el aspecto de la pagina así como esconder menús y delimitar de manera visual 
las distintas partes de la página lo que permite mejorar la experiencia de usuario
haciendo más accesible las partes importantes de la página.


Ésta última mención a la interfaz de usuario es importante ya que es uno de los puntos
que más se cuidan en las empresas e incluso se hacen estudios para mejorar las interfaces
, por ejemplo, debido al tamaño de los nuevos \emph{smartphones} el menú de navegación
ha cambiado su posición debido a que era difícil alcanzar la parte superior de la pantalla
y por tanto se hacía molesto el uso de la aplicación.

\newpage
\section{AFRAME}
\label{sec:aframe}

\textbf{\emph{AFRAME}} es un entornos web para la construcción de escenas de realidad
virtual, se creó con la intención de facilitar la creación de contenido de realidad 
virtual. Es un entorno de código libre y tiene una de las comunidades de creadores de
realidad virtual más grandes actualmente.

Soporta la mayoría de gafas de realidad virtual como \emph{Vive, Rift, GearVR, etc.} 
además se puede usar no solo para realidad virtual sino para realidad aumentada. AFRAME 
fomenta la creación de escenas inmersivas completas de realidad virtual y va más allá
de únicamente generar contenido en 360º, también implementa el uso de control de posición 
y controladores (mandos) que permiten interactuar con la escena, estos controles permiten
al usuario tener una experiencia más inmersiva en la escena.

AFRAME además está soportado en los siguientes escenarios:
\begin{itemize}
	\item Realidad virtual en aplicaciones de escritorio con \emph{gadgets}.
	\item Realidad virtual en aplicaciones móviles con \emph{gadgets}.
	\item Aplicaciones de escritorio convencionales.
	\item Aplicaciones de móvil convencionales.
\end{itemize}


A continuación se explican en subsecciones las características más importantes del 
entorno AFRAME.

\subsection{Primitivas y HTML}
\label{subsec:aframe_primitivas}

\emph{AFRAME} está basado en HTML y el DOM \emph{(Document Object Model)}, HTML es un lenguaje
sencillo de leer y conocer la estructura, además no requiere de instalaciones únicamente se compone
de texto y un navegador que muestre la página. AFRAME es compatible con la mayoría de entornos
que se utilizan actualmente en el desarrollo web como pueden ser Vue.js, React, AngularJS y jQuery.

Crear escenas de realidad virtual de manera muy simple, como se ve en la figura~\ref{fig:aframe-scene}
únicamente se necesita una etiqueta \textbf{script} que haga referencia al código del entorno y una
etiqueta \textbf{a-scene} dentro del cuerpo del documento para crear una simple escena. 

AFRAME ofrece un conjunto de elementos básicos para la escena llamados primitivas, estos elementos
son figuras básicas como \emph{cajas, esferas, cilindros, planos, cielo, etc.} AFRAME no solo ofrece
figuras básicas, como hemos comentado anteriormente su intención es la de crear escenas inmersivas
completas, por ello ofrece además etiquetas para la inyección de sonidos y vídeos dentro de la escena.

Este tipo de primitivas son bastante útiles para su uso en escenas simples, todas ellas heredan 
de la primitiva \textbf{a-entity} que, equiparandolo con HTML convencional, equivaldría con la
etiqueta \textbf{div} del estándar HTML, la cual se utiliza de muchas maneras distintas.

Esta etiqueta \textbf{a-entity} representa por tanto el punto de partida de cualquier tipo de elemento
de la escena que queramos crear al cual se le irán añadiendo \emph{componentes} que le dotarán de
cierta funcionalidad específica.

AFRAME permite además crear nuestras propias primitivas lo que nos permite seguir el principio de 
programación \emph{DRY (Don't Repeat Yourself)} por el cual si tenemos un complicado elemento en la
escena que está compuesto de varias entidades distintas no tenemos que copiar ese código \emph{N} veces
sino que podemos registrar la primitiva y hacer referencia a este elemento mediante el nombre de 
etiqueta que más convenga.

La figura ~\ref{fig:aframe-scene} muestra todo el código necesario para crear la escena mostrada.
\begin{figure}[h]
	\centering
	\includegraphics[width=13cm, height=4cm]{img/html-aframe.png}
	\includegraphics[width=13cm, height=6cm]{img/aframe-scene.png}
	\caption{Ejemplo de código HTML que renderiza una escena básica de realidad 
	virtual}
	\label{fig:aframe-scene}
\end{figure}
	
	
	
\subsection{Sistema Entidad-Componente}
\label{subsec:entidad_componente}
AFRAME se basa en el entorno \emph{\textbf{three.js}} y provee una estructura reutilizable de entidad-
componente en la que un componente puede ser utilizado en distintas entidades de distinta clase.
Se pueden generar componentes personalizados y vincularlos a cualquier tipo de 
entidad dándole una funcionalidad distinta. Esto permite una gran flexibilidad a la 
hora de generar distintos integrantes en la escena con funcionalidades diferentes
pero heredando todos de una misma entidad.

La arquitectura entidad-componente es común en el desarrollo 3D y en el desarrollo de videojuegos y 
sigue el principio de composición por herencia. Los beneficios de este tipo de arquitectura son:

\begin{itemize}
	\item Gran flexibilidad a la hora de crear objetos debido a la reutilización de componentes y 
	el mezclado de distintos componentes.
	\item Elimina el problema de largas cadenas de herencia, cada componente es independiente.
	\item Diseño limpio gracias al desarrollo por módulos.
	\item Es la manera más escalable de generar complejas escenas de realidad virtual.
	\item Permite reutilizar y compartir componentes no solo en un mismo proyecto sino con la comunidad
	de desarrolladores.
\end{itemize}

En la figura ~\ref{fig:ecs} se muestra un esquema del \emph{Sistema Entidad-Componente} en el cual
tenemos una figura final con forma de caja la cual estaría compuesta de varios componentes distintos. 
Estos componentes son: \textbf{Posición, Geometría, Material y Color}.

\begin{figure}
\centering
	\includegraphics[width=15cm, height=3cm]{img/ecs.png}
	\caption{La siguiente figura muestra etiquetas que serían el equivalente en AFRAME a un componente,
	el conjunto de varios componentes dan forma a la caja}
	\label{fig:ecs}
\end{figure}

A continuación se mostrará la API \emph{(Application Program Interface)} que ofrece AFRAME para 
implementar el \textbf{Sistema Entidad-Componente}:
\begin{itemize}
	\item \textbf{Entidad:} se representa en AFRAME mediante la etiqueta \textbf{a-entity}.
	\item \textbf{Componentes:} se representa en AFRAME como atributos de la etiqueta HTML. Estos 
	componentes son objetos que contienen un esquema, manejadores y métodos. Éstos se registran mediante
	el método \textbf{AFRAME.registerComponent(nombre, definición);}. A continuación se muestra un 
	componente que imprime un mensaje en la consola del navegador.
	\begin{figure}[h]
		\centering
		\includegraphics[width=12cm, height=3cm]{img/componente-aframe.png}
		\caption{Componente básico que imprime por la consola del navegador el mensaje que se le pase
		por \emph{message}}		
		\label{fig:componente}
	\end{figure}
	
	\item \textbf{Sistema:} representado por la escena mediante la etiqueta \textbf{a-scene}. Los 
	sistemas son similares a los componentes a la hora de definirlos, se registran mediante
	\textbf{AFRAME.registerSystem(nombre, definición)}.
\end{itemize}

Además como hemos comentado AFRAME tiene dos tipos de implementaciones que le dan características 
adicionales al sistema entidad-componente y es que al implementarse sobre HTML y JavaScript tenemos
dos características importantes:

\begin{itemize}
	\item Referenciar una entidad mediante el método \textbf{querySelector} implementado en JavaScript
	lo que permite acceder a una entidad por su ID, clase o atributos. En la figura ~\ref{fig:querySel}
	se muestra un ejemplo de código JavaScript que accede a un elemento de AFRAME con ID
	\emph{rightHand}.
	\begin{figure}[h]
		\centering
		\includegraphics[width=13cm, height=0.5cm]{img/querySelector-aframe.png}
		\caption{Ejemplo de acceso a un elemento de AFRAME, como se aprecia se hace de la misma
		manera que se accede a cualquier elemento de HTML convencional}
		\label{fig:querySel}
	\end{figure}
	
	\item Comunicación entre las entidades mediante eventos, esta característica es hereditaria del 
	lenguaje utilizado lo que permite registrar y suscribir eventos que permite que los elementos en
	la escena no se conozcan entre sí.
	
	\item Crear, eliminar y modificar atributos mediante el API del DOM, podemos utilizar los métodos
	\textbf{.setAttribute, .removeAttribute, .createElement y .removeChild} para modificar los 
	elementos.
	
\end{itemize}

Por último pero no más importante, los componentes pueden hacer cualquier cosa, tienen acceso completo
a \textbf{three.js, JavaScript y APIs Web} como pueden ser \emph{WebRTC, AJAX, etc.}

\subsection{Modelos 3-D}
\label{subsec:modelos-3d}

\textbf{AFRAME} ofrece la posibilidad de cargar modelos 3D más sofisticados en los formatos 
\emph{glTF, OBJ, COLLADA}. Se recomienda el uso del formato \emph{glTF} ya que es el modelo estándar
para transmitir modelos 3D en la WEB. Los componentes se pueden escribir de manera que se pueda manejar
cualquier tipo de formato que tenga un objeto en \emph{three.js} para cargar el modelo.

Los modelos son archivos en texto plano y contiene vértices, caras, texturas, materiales y animaciones.

Como se ha repetido en varias ocasiones se trata de crear escenas, para ello es necesario implementar 
animaciones. Estas animaciones se implementan con el paquete de componentes creado por
\textbf{Don McCurdy}, se puede localizar en \url{https://github.com/donmccurdy/aframe-extras/blob/master/src/loaders/animation-mixer.js}.

\subsection{Herramientas de Desarrollo}
\label{subsec:devtools}

\textbf{AFRAME} como hemos comentado se construye sobre JavaScript y HTML por tanto utiliza las mismas
herramientas de desarrollo ya disponibles dentro del navegador. Además al crear escenas 3D se hace 
complicado depurar la escena y saber que todo está siendo representado en su posición correcta, para 
esta problemática AFRAME incluye un inspector visual que permite conocer la posición y los valores de 
los atributos para cada entidad de la escena. La figura ~\ref{fig:aframe-scene} muestra la escena de
nuestro simulador y los atributos de la cámara incluida dentro del robot, como se ve el inspector
muestra el ángulo de visión de la cámara del robot y muestra los ejes de la escena respectivo al punto
en el que se encuentra de la cámara.\\

Ofrece una representación en árbol de la escena siguiendo la estructura del documento HTML, el inspector
ofrece la posibilidad de mover, rotar, añadir y borrar elementos de la escena así como copiar la 
etiqueta una vez movida para usarla en nuestro documento HTML. Un ejemplo de esto sería mover nuestro
robot y orientarlo de cara a la pelota verde, sin el inspector tendríamos que ir haciendo pruebas 
modificando manualmente el atributo de la posición dentro del documento HTML pero con el inspector 
visual basta usar las herramientas para mover el elemento y copiar las coordenadas que aparecen
en la ventana de la derecha.

Por último el inspector permite hacer capturas de movimiento lo que permite:
\begin{itemize}
	\item Test más rápidos, no se necesitan utilizar los \emph{gadgets} cada vez que se quiera hacer 
	un test lo que acelera mucho el desarrollo de la aplicación.
	
	\item Múltiples desarrolladores pueden utilizar el mismo \emph{gadget}, puedes grabar el movimiento
	y dejar de usar el \emph{gadget} para que otros desarrolladores del mismo proyecto puedan usarlo.
	
	\item Mostrar errores del código.	
	
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[width=13.4cm, height=6.3cm]{img/aframe-inspector.png}
	\caption{Inspector visual que ofrece el entorno \emph{AFRAME}}
\end{figure}


\newpage
\section{ACE Editor}
\label{sec:ace_editor}

\textbf{\emph{ACE Editor}} es un editor de código embebido creado en \emph{JavaScript}, implementa las 
características de los editores nativos como \emph{Sublime Text, Vim, etc.} \emph{ACE} es el editor
usado en el servicio \emph{AWS Cloud9 IDE}.

El editor ofrece la siguiente funcionalidad:
\begin{itemize}
	\item Mantener el estado de la sesión como por ejemplo el \emph{scroll}, selección de texto, etc.
	\item Resaltado de sintaxis para la mayoría de lenguajes de programación como \emph{JavaScript, CSS
	, Python, Java, etc.}
	\item Permite crear tus propias reglas de resaltado.
	\item Indentación automática del código.
	\item Manejo de ficheros grandes, maneja miles de líneas sin problema.
	\item Resaltado de paréntesis.
	\item \emph{Drag and Drop} de texto dentro del editor de código.
	\item Comprobación de sintaxis del lenguaje, esta característica es bastante útil ya que nos permite
	descartar errores en ejecución debido a la sintaxis del programa lo que acelera el desarrollo.
\end{itemize}

La característica más importante para nuestro proyecto es sin duda la facilidad para embeberlo dentro
de nuestra aplicación, simplemente hace falta una etiqueta \textbf{script} y un pequeño código para
configurar su carga en la página, el detalle del código se mostrará en el capítulo \ref{chap:disenno}.
El editor además provee de una sencilla \emph{API} para poder obtener el código escrito en el editor
a través de nuestro programa para poder manejarlo.

En la figura a continuación se muestra las posibles configuraciones que puede adoptar el editor.

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm, height=6cm]{img/ace-config.png}
	\caption{Posibles parámetros de configuración para el editor}
	\label{fig:ace-conf}
\end{figure}


El editor utiliza el DOM \emph{(Document Object Model)} para el renderizado, concretamente la etiqueta
\textbf{canvas} y no depende de librerías externas. La característica más destacable de el editor es que 
no es necesario instalar nada tu ordenador, el editor reside completamente en la página web lo que 
permite la creación de aplicaciones interactivas como la del presente proyecto en la cual podemos 
programar el robot 'en vivo' sin la necesidad de tener que exportar el código de nuestro editor para 
hacer pruebas en la simulación.


\newpage
\section{Blockly}
\label{sec:blockly}

\textbf{\emph{Blockly}} es una librería que permite aprender programación mediante el uso de bloques
visuales que se pueden combinar y traducir posteriormente a distintos lenguajes. Permite
a los usuarios programar en distintos lenguajes sin tener que conocer la sintaxis del lenguaje al 
detalle.\\

Es una forma de aprender a programar orientada a estudiantes de temprana edad, el objetivo es que el 
alumno pueda aprender la lógica de los algoritmos de programación pero sin tener que aprender todo el
lenguaje como puede ser declaración de variables, tipo y en general la sintaxis propia del lenguaje
que según el tipo de lenguaje puede ser pesado al principio.

\emph{Blockly} es la base de otros entornos de programación visual como \emph{\textbf{Scratch 3}} ya
que es código libre lo que permite a cualquier desarrollador contribuir y utilizarlo en su propia 
aplicación. Ofrece métodos para importar y exportar el código de bloques además de métodos para 
modificar y personalizar el aspecto de los bloques para que sigan el estilo de la interfaz de 
la aplicación.

Es una tecnología orientada completamente al lado cliente y se puede utilizar mediante el fichero 
comprimido del repositorio oficial de \emph{Blockly} llamado \emph{blockly-compressed}, no 
utiliza dependencias y como ya hemos comentado es código libre.

\subsection{Generadores de código}
\label{subsec:blockly-generadores}

\emph{Blockly} como hemos comentado provee de generadores de código para los siguientes lenguajes:
\begin{itemize}
	\item JavaScript.
	\item Python.
	\item PHP.
	\item Lua.
	\item Dart
\end{itemize}

Estos generadores proveen las herramientas básicas para crear funciones, expresiones lógicas, bucles,
etc. La problemática de esto es que a veces nuestras aplicaciones necesitan usar la API de otras 
dependencias como en nuestro caso, para solventar esto \emph{Blockly} permite generar bloques 
personalizados que se traducirán a la instrucción necesaria dotando de mucha flexibilidad al entorno.\\

Además \emph{Blockly} permite añadir palabras reservadas dentro de cada tipo de lenguaje lo cual 
nos permite un control de colisiones con las variables propias de la aplicación ya que en lugar de 
eliminar esta variable lo que hace \emph{Blockly} es renombrar todas las apariciones de la variable 
en el código generado dinámicamente.\\

Se puede apreciar que el código generado a través de los bloques será correcto en su sintaxis pero hay
una problemática presente en programación y es la aparición de \emph{bucles infinitos}, la librería 
dota de un método para intentar aplacar esta problemática, en la figura ~\ref{fig:loop-trap} se muestra
un simple código que cuenta el número de iteraciones del bucle, no es el mejor método para solventar el 
problema ya que, como es nuestro caso, necesitaremos bucles de ejecución continua pero dota a la 
aplicación de control de ejecución de código.

\begin{figure}[h]
	\centering
	\includegraphics[width=14cm, height=1.2cm]{img/loop-trap.png}
	\caption{Implementación de un contador para evitar bucles infinitos al traducir lenguaje de 
	\emph{Blockly}}
	\label{fig:loop-trap}
\end{figure}

\subsection{Bloques personalizados}
\label{subsec:custom-blocks}

Como se ha hecho referencia en la sección anterior, \emph{Blockly} permite además de generar código 
en distintos lenguajes también crear bloques personalizados lo que permite generar código a través de 
bloques y conectarlos con cualquier tipo de API.\\

Para generar bloques personalizados \emph{Blockly} hemos de configurar varios aspectos:

\begin{itemize}
	\item Configuración de los parámetros de entrada y salida del bloque, conectores o parámetros
	en línea y color. La configuración del bloque se permite mediante dos formas distintas a través
	de un JSON o mediante JavaScript registrando un nuevo bloque en el objeto \textbf{Blockly}. La 
	figura ~\ref{fig:block-definition} muestra ambos métodos para generar el mismo bloque.
	\begin{figure}[h]
		\centering
		\includegraphics[width=10cm, height=5cm]{img/block-json.png}
		\includegraphics[width=10cm, height=3cm]{img/block-js.png}
		\caption{Modos de configuración de un bloque personalizado en \emph{Blockly}, como se puede 
		apreciar la declaración de las distintas partes del bloque es bastante intuitiva y los
		parámetros son autodescriptivos.}
		\label{fig:block-definition}
	\end{figure}
	
	\item Configuración de la traducción del bloque a la instrucción de interés en los distintos 
	lenguajes necesarios. 
	
	\item Iniciar el bloque para que se renderice en el editor de bloques visual. La figura 
	~\ref{fig:block-init}
	\begin{figure}[h]
		\centering
		\includegraphics[width=6cm, height=3cm]{img/block-init.png}
		\caption{Muestra del código que inicia el bloque para que se muestre en el editor visual, 
		\emph{moveBlock} representa un objeto JSON con la configuración del bloque}
		\label{fig:block-init}
	\end{figure}
	
\end{itemize}

Como se ve aunque los parámetros del JSON son autodescriptivos y sencillos de entender es complicado
y lento generar un bloque desde cero por tanto \emph{Google} ofrece unas herramientas para 
desarrolladores en línea lo que permite acelerar esta generación de código.


En la figura ~\ref{fig:dev-tool} se muestra una imagen del entorno de creación de bloques personalizados 
que provee \emph{Blockly} en el cual se puede observar en la parte de la derecha el archivo en formato
\emph{JSON} \emph{(JavaScript Object Notation)} de configuración del bloque en el que se definen las 
entradas que toma, el color con el que se mostrará entre otra serie de parámetros. Además, muestra
la función con la configuración básica para obtener los parámetros que se utilizaran para generar
código real JavaScript.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=16cm, height=7cm]{img/custom-block.png}
	\caption{Herramienta de desarrollo para generación de bloques personalizados.}
	\label{fig:dev-tool}
\end{figure}

Como se ve en la figura ~\ref{fig:dev-tool} en la parte superior derecha la herramienta te muestra cómo
se verá el bloque final en tu aplicación bajo la configuración visual por defecto que trae 
\emph{Blockly}

\subsection{Menú de bloques, \emph{Toolbox}}

El editor de \emph{Blockly} provee además de una barra de herramientas en la cual se muestran los 
bloques que podrán ser usados a través del editor, estos bloques se configuran a través de un fichero 
XML en el cual podemos tener distintos tipos de etiquetas que se muestran a continuación.

\begin{figure}
	\centering
	\includegraphics[width=11cm, height=2cm]{img/toolbox-xml.png}
	\caption{Ejemplo de las etiquetas posibles de configuración de la \emph{toolbox} del editor}
	\label{fig:xml-toolbox}
\end{figure}

Como vemos en la figura ~\ref{fig:xml-toolbox} tenemos tres bloques distintos, la raíz del XML marcada
por la etiqueta \emph{xml}, la etiqueta \emph{category} que nos permite hacer divisiones de bloques por
tipos distintos, en la imagen tenemos dos categorías \emph{variables y texto}, la categoría 
\emph{variables} como vemos no tiene bloques dentro ya que se generan dinámicamente. En la categoría
\emph{texto} vemos declarado un bloque de tipo \emph{text} que representaría un \emph{String} en 
lenguaje JavaScript. Como se puede apreciar la configuración del menú de bloques no es fija, se puede
crear distintas categorías en función del diseño de la interfaz de usuario.



\newpage
\section{jQuery}
\label{sec:jquery}

\textbf{\emph{jQuery}} es una librería multiplataforma de \emph{JavaScript}, creada inicialmente por 
John Resig y permite simplificar la forma de interactuar con los documentos HTML, el DOM, manejo de 
eventos, desarrollo de animaciones y agregar interacción ligera entre el cliente y servidor con el 
mecanismo \emph{AJAX (Asyncronous JSON And XML}. Es una biblioteca ampliamente utilizada debido
a las características que ofrece y sigue la filosofía \emph{' Code less, do more '}.\\


\emph{jQuery} es software libre de código abierto, posee una licencia doble MIT y una licencia pública
general de GNU v.2 lo que permite su uso en proyectos libres y privados. jQuery se basa en simplificar 
funcionalidad que se repite a menudo en las páginas web como por ejemplo manejo de evento 'click' de un
botón, ocultar o mostrar un elemento del DOM, etc.

Basados en \emph{jQuery} existen una gran cantidad de plugins (extensiones) gratuitos y de pago
que permiten disminuir el tiempo de desarrollo de la interfaz de usuario como por ejemplo hacer
que tu pagina web sea \emph{responsive} (que el contenido se adapte bien al tipo de dispositivo y 
navegador), crear una galería de fotos, carrusel de imágenes, etc. 

Una de las características de \emph{jQuery} más importante es su facilidad de uso, la curva de 
aprendizaje de jQuery es sencilla ya que como hemos comentado ofrecen métodos para manejo incluso de 
CSS. La figura ~\ref{fig:jquery} muestra cómo se hace un efecto de \emph{'fundido'} con jQuery, como 
se ve en la figura el método puede tomar parámetros de entrada para regular la velocidad a la que se
quiere realizar el efecto.

\begin{figure}[h]
	\centering
	\includegraphics[width=8.5cm, height=0.5cm]{img/jquery-fadein.png}
	\caption{Instrucción para hacer un efecto de \emph{'fundido'} en jQuery.}
	\label{fig:jquery}
\end{figure}
 
En la parte de la derecha de la instrucción tenemos el método a ejecutar y la velocidad, en la parte
de la izquierda tenemos el acceso completo al dom para un elemento en concreto.\\

Para hacer este tipo de efectos es necesario conocer bien el uso del lenguaje CSS, jQuery permite 
a desarrolladores novatos en el campo de maquetación de interfaces de usuario hacer que sus páginas 
web sean algo más elaboradas en cuanto a efectos e interfaz se refiere sin la necesidad de conocimiento
profundo de CSS3.\\

Actualmente en el punto en el que se encuentra el desarrollo web \emph{jQuery} ha disminuido su uso
debido a la aparición de entornos como \emph{React, VueJS y AngularJS} que implementan
funcionalidad similar a la de jQuery pero además permiten implementación de patrones de diseños como
el \emph{MVC (Modelo Vista-Controlador)}. Pero este tipo de modelos no son necesarios en el proyecto 
que nos concierne de ahí la elección de jQuery por encima de estos otros entornos.

\newpage
\section{NPM y Webpack}
\label{sec:npm}

\emph{\textbf{NPM}} es la abreviatura de (Node Package Management), es una tecnología de gestión de 
dependencias del entorno NodeJS lo cual permite la simplificación de instalación de las dependencias
de un determinado software.\\

La declaración de dependencias de la aplicación se hace en el fichero \emph{package.json} en el cual
se pone los distintos paquetes NPM de los que hará uso nuestra aplicación tanto para un entorno de 
desarrollo como para un entorno de producción. Haciendo referencia a esto mencionamos 
\emph{\textbf{WebPack}} que es una herramienta de empaquetado de aplicaciones lo que permite generar un
\emph{bundle} con todo lo necesario de nuestra aplicación haciendo que el uso de nuestra aplicación
en el HTML se simplifique necesitando únicamente una etiqueta \textbf{script} que referencie a nuestro
\emph{bundle}.\\

La instalación con NPM es simple, basta con moverse al directorio en el que se encuentra nuestro 
fichero \emph{package.json} y ejecutar \emph{npm install}, esto descargará todas las dependencias
de nuestra aplicación e incluso las dependencias de nuestras dependencias (si existieran) y las 
instalará bajo la carpeta \textbf{node-modules}. La referencia en el nombre de \emph{Node} es debido
a que el entorno \textbf{Node} tiene una simplificación para hacer uso de las librerías en la carpeta
\emph{node-modules} mediante la instrucción \textbf{require} la cual busca dentro de la carpeta la que
se llame igual que la que pasamos como parámetro a la función.\\

Para la utilización de estas librerías en el lado cliente tenemos que hacer uso de ES6 y la 
instrucción \emph{import}. Ésto unido con \emph{Webpack} permite que todas las dependencias en el lado
cliente (imports) se junten en un único fichero.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DISEÑO E IMPLEMENTACIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Diseño e implementación}
\label{chap:disenno}

En este capítulo se mostrará la estructura del proyecto y se desarrollarán cada una de las partes
explicando la funcionalidad de cada una.

\begin{figure}[h]
  \centering
  \includegraphics[width=13cm, keepaspectratio]{img/websim-estructura.png}
  \caption{Esquema que presenta la estructura del simulador WebSim.}
  \label{fig:arquitectura}
\end{figure}

\section{Arquitectura}
\label{sec:arquitectura}

Como se comentó en la sección ~\ref{sec:objetivo_general} el objetivo del siguiente proyecto es crear 
la base de una aplicación para simular robots en el entorno \emph{AFRAME} permitiendo conectar un editor
de código para ejecutar instrucciones con el robot simulado.

En la figura ~\ref{fig:arquitectura} se muestra el esquema que sigue el simulador WebSim, a continuación
se explicará cada una de las partes por separado y la comunicación existente entre ellas.

El diseño como se puede apreciar en la figura ~\ref{fig:arquitectura} sigue un diseño por módulos,
la intención es poder conectar distintos tipos de entradas a WebSim como puede ser un editor, Blockly,
ICE, etc. sin tener una aplicación monolítica en la que todas las partes estén completamente acopladas.\\

WebSim tiene varios roles:

\begin{itemize}

	\item La funcionalidad más importante de WebSim es que se encarga de controlar la ejecución del
	\emph{mundo}, es decir, sabe cuándo el robot está ejecutando un código y cuándo no y permite
	arrancar o pausar el robot. Se muestra en la figura ~\ref{fig:arquitectura} mediante el bloque
	\textbf{Métodos para ejecutar y parar el código}. Una de las funcionalidades del control del entorno
	es evitar que el usuario cambie el valor de la variable \emph{myRobot} lo cual haría que se perdiese
	el objeto robot y tener que refrescar la página.
	
	\item Se encarga de ofrecer la conexión simplificada con el robot simulado en el entorno AFRAME que
	como ya se ha explicado es la abstracción de nuestro robot real, por tanto \emph{WebSim} ofrece un 
	\textbf{HAL API} \emph{(Hardware Abstraction Layer)} lo que simplifica mucho el uso del robot
	creado en AFRAME, podemos enviarle instrucciones que el robot ejecutará mediante una única línea
	de código, lo que permitirá al usuario crear una lógica para el robot de una manera limpia sin
	tener que comunicarse directamente con el motor \emph{AFRAME}, de eso se encarga \emph{WebSim}.
	
	\item Ofrece la instancia que contiene el objeto robot \emph{(myRobot)} de manera que el usuario
	no tiene que instanciar ningún tipo de variable de la clase \emph{RobotI} ya que se le ofrece para
	el uso directo. Esto conlleva una doble funcionalidad, primero simplifica el uso del simulador aún
	más ya que el usuario solo tiene que enviar instrucciones y segundo que evitamos la creación de dos
	instancias del mismo objeto que llevaría a una incorrecta ejecución.
	
	\item Ofrece una interfaz de escucha de eventos en la cual el editor o la parte que se conecte
	con \emph{Websim} recibe el código que se quiere ejecutar y llama a los métodos necesarios para 
	ejecutar el código que hace uso del robot simulado que como ya se ha comentado en el punto anterior
	está contenido en la variable global de \emph{WebSim} llamada \textbf{myRobot}. Esto permite 
	conectar distintos tipos de 'puertas' para ejecutar código en el robot simulado como pueden ser
	las interfaces \textbf{ROS Y ICE}.	

	\item Por último como se ha comentado una de las dependencias de \emph{WebSim} es el entorno
	\emph{AFRAME}, para la simulación del robot ha sido necesario crear tres componentes llamados
	\textbf{followBody, spectatorComponent, intersectionHandler} y es \emph{WebSim} el encargado de 
	registrar estos componentes haciendo uso de los métodos que ofrece \emph{AFRAME}, la figura 
	~\ref{fig:custom-components} muestra la forma de registrar los nuevos componentes.
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=13cm, height=1.6cm]{img/aframe-components.png}
		\caption{Registro de los tres componentes necesarios para el Robot simulado.}
		\label{fig:custom-components}
	\end{figure}
\end{itemize}

Como se puede ver se cumple el objetivo fijado en el inicio y es proveer de una capa de simplificación
y abstracción para los usuarios de modo que ellos solo se tienen que concentrar en generar un código
para ejecutar una serie de instrucciones en el robot accediendo de forma simple a los distintos sensores
como son la cámara, motores, sensores de ultrasonido y sensores infrarrojos. \\

Principalmente el usuario se encargará de programar la lógica del robot, es decir, el pensamiento 
(código) para resolver un ejercicio determinado con el objetivo de aprender programación de robots.
Algunos ejemplos de ejercicios soportados son sigue línea, seguimiento de objeto mediante filtrado
de colores y evitar obstáculos mediante el control de posición. A continuación se muestran enlaces a
los ejercicios resueltos.


\newpage
\section{Simulación con AFRAME}
\label{sec:simulacion}

En esta sección se explicará como se ha creado la simulación 3D de nuestra escena con el entorno 
\emph{AFRAME}. \\

Como hemos explicado en la sección ~\ref{sec:aframe} \emph{AFRAME} simplifica en gran parte la 
generación de escenas en el navegador, se monta sobre \emph{WebGL y three.js} y permite crear la escena
y sus integrantes (entidades) haciendo uso únicamente de etiquetas HTML. En la siguiente figura se 
muestra el esquema HTML necesario para generar nuestra escena junto con nuestro robot.

\begin{figure}[h]
	\centering
	\includegraphics[width=15cm, height=8cm]{img/aframe-sim.png}
	\caption{HTML que genera la escena principal del simulador}
	\label{fig:escena-simulador}
\end{figure}

Ahora se explicarán cada una de las partes del HTML de la figura ~\ref{fig:escena-simulador}, se 
explicarán las que no sean entendibles de manera directa.\\

Como hemos comentado en el capítulo ~\ref{chap:herramientas} la etiqueta \textbf{a-scene} es la 
etiqueta principal utilizada en \emph{AFRAME} para generar la visualización, en nuestro caso como 
queremos una escena simple le hemos dado un color de fondo gris y hemos activado las físicas y 
mediciones. Las físicas permite hacer uso del motor de físicas en el paquete \textbf{aframe-physics}
en el cual existe la gravedad, rozamiento y otros tipos de fuerzas. La etiqueta \textbf{stats} nos 
permite conocer las métricas relevantes de la escena como los \emph{FPS} (Frames por segundo), el 
número de vértices que está manejando la escena, las texturas cargadas en la escena y los \emph{RAF}
(Request Animation Frame) que es la latencia de la escena. Estas medidas aparecen en rojo cuando 
el valor no es el adecuado para cada una de ellas, permiten al desarrollador medir la eficiencia de 
su escena y de el código bajo ésta.\\

Las etiquetas \textbf{a-assets} son un modo de \emph{AFRAME} de gestionar de manera más eficiente 
las texturas y modelos 3D a usar en las entidades de la escena. Podemos usar la etiqueta
\textbf{a-asset-item} con cualquier tipo de archivo de entrada, llama al cargador de ficheros de 
\emph{three.js} y 'avisa' del estado de la carga del archivo, tiene tres estados:

\begin{itemize}
	\item Error: Fallo al cargarlo.
	\item Progress: lo emite cuando está en proceso de carga del archivo, devuelve un evento en el cual
	en el campo \emph{detail} tenemos un objeto de tipo \textbf{XMLHTTPRequest} con la cantidad
	de bytes cargados en total.
	\item Loaded: Indica que el archivo ha cargado correctamente.
\end{itemize}

Como hemos explicado en el capítulo ~\ref{chap:herramientas}, el 'objeto' básico en una escena en 
\emph{AFRAME} es \textbf{a-entity} que es un objeto vacío al que le podemos conectar y dar
la funcionalidad que requiramos. Haciendo uso de ésto hemos podido simular nuestro robot, nuesto robot
se compone de ruedas, sensores y cámara.\\

Para la simulación del cuerpo del robot hemos utilizado el atributo \textbf{collada-model} que nos 
permite hacer uso de un modelo 3D en formato \emph{.dae} y anclarlo a nuestra entidad de la escena. Se
pueden usar otro tipo de formatos pero hemos tomado éste ya que era el que mejor rendimiento daba
al cargarlo en la escena. Además se ha utilizado el atriburo \textbf{dynamic-body}, éste atributo lo 
que hace es dotar de físicas a ese elemento con la particularidad que el elemento puede ser movido
por otros, en la imagen también se ve el atributo \textbf{static-body} que también es dotado de físicas
pero de una manera distinta, las entidades con éste atributo no pueden ser movidos, se usa en general
para el suelo, paredes y en general entidades que no han de ser movidas en la escena.

El robot además tiene la cámara y sensores de ultrasonido, para los sensores de ultrasonido se ha 
utilizado el atributo \textbf{raycaster} que se encapsula dentro de la entidad con el identificado
\textbf{positionSensor} junto con el componente \textbf{followBody}. La carga de estos elementos
se hace desde WebSim, es necesario hacerlo así para poder modificarlos dinámicamente y añadir
más o menos sensores al robot.

Por último tenemos la cámara, como vemos es un elemento hijo encapsulado dentro de una entidad, esto
se hace así debido a las recomendaciones de \emph{AFRAME} que indican que para modificar la posición
de la cámara incluyamos esta dentro de una entidad. La etiqueta cámara cuenta con atributos entre los
que destacaremos dos \textbf{spectator y wasd-controls-enabled}.

\begin{itemize}
	\item Spectator: Este atributo ha sido creado específicamente para la aplicación y permite 
	imprimir el contenido de la cámara en una etiqueta \textbf{canvas} dentro de la página
	HTML lo que permite imprimir lo que está viendo el robot.
	
	\item WASD-Controls-Enabled: Permite declarar si la cámara se podrá mover con las teclas W-A-S-D, 
	en nuestro caso no nos interesa ya que modificaríamos la posición de la cámara respecto del robot
	estropeando así la escena.
\end{itemize}

La etiqueta \textbf{a-sphere} declara la existencia de una esfera en nuestra escena, los atributos 
declaran las siguientes propiedades de la esfera, es de la clase 'collidable' esto se utiliza para
indicar al robot que los sensores de ultrasonido van a detectar intersecciones con este tipo de objetos
, la esfera también tiene físicas aplicadas y tiene una masa de 1000kg.

La etiqueta \textbf{a-plane} indica la existencia de un plano horizontal, este plano tiene físicas pero
es un cuerpo estático, es decir, no puede ser movido por otros objetos de la escena. Además se
declara el tamaño del plano, la textura a cargar en el plano que en este caso será nuestro circuito en 
blanco y negro y el número de veces que se repite a lo largo de los ejes X y Z. Como hemos indicado que
solo se repita 1 vez en ambos ejes lo que hace \emph{AFRAME} es estirar la textura hasta ajustarla con
el tamaño del plano.

Por último tenemos dos etiquetas \textbf{a-light} que indica que se va a utilizar una luz en la escena
de tipo ambiental de color blanco y la etiqueta \textbf{a-entity} que declara una entidad vacía 
que como se ha explicado antes se usa para posicionar la cámara principal de la escena.

\newpage
\section{Drivers del robot}
\label{sec:drivers}

En el siguiente apartado se explicará cada una de las partes del objeto robot \emph{(HAL API)} su
funcionalidad y cómo ha sido implementado, las partes que se implementan se encuentran 
enumeradas en la sección ~\ref{sec:objetivos_especificos}. 
% RECORDATORIO: ahora explicas los motores y todas las funciones como se arranca y todo

Estos sensores implementados en el robot recogen una serie de datos que han de ser guardados 
de manera interna en el robot para que el usuario pueda llamar a estos datos y programar una lógica
en función de estos, para ello se crean una serie de métodos que se conectan con el robot simulado en
AFRAME y variables internas para guardar los datos y servirlos mediante una instrucción simple.\\

En el robot tenemos dos hebras independientes, la hebra de los motores y la hebra de recogida de la
cámara. Son funciones autónomas que se llaman así mismas cada cierto tiempo.


\subsection{Constructor}

El constructor de la clase \emph{RobotI} es un método obligatorio en \emph{JavaScript}, es el primer
método al que se llama una vez se crea una instancia del objeto.\\

El constructor de nuestro objeto toma como parámetro de entrada un \emph{string} con el identificador
de la etiqueta HTML (etiqueta del entorno AFRAME) en la cual tenemos nuestro robot simulado para poder
hacer uso de las propiedades que ofrece el entorno AFRAME como puede ser la posición en la escena, 
añadir o eliminar elementos en la escena, obtener la imagen de la cámara, etc. \\

Además de acceder al robot simulado de AFRAME el constructor lo que hace es iniciar una serie de 
variables internas del robot (\emph{this} hace referencia al contexto del objeto robot):

\begin{itemize}
	\item \textbf{defaultDistanceDetection}: Es una variable de configuración de los sensores de 
	ultrasonido que permite declarar la distancia máxima a la cuál los sensores detectarán un objeto,
	en nuestro caso se ha puesto hasta 10 metros.
	
	\item \textbf{defaultNumOfRays}: Es una variable de configuración de los sensores de ultrasonidos,
	declara el número de láseres que se simularán para detectar objetos igual que lo haría un 
	sensor de ultrasonidos. El arco que abarcamos es 180º por lo tanto cuantos mayor sea el número 
	configurado mejor será la detección de objetos.
	
	\item \textbf{this.robot}: Es una variable que permite crear un link entre la abstracción de 
	nuestro objeto robot y el robot simulado en AFRAME y nos permite acceder a los distintos
	métodos que ofrece AFRAME por defecto.
	
	\item \textbf{this.activeRays}: Es una variable de control de tipo \emph{boolean} que nos permite
	saber si los láseres del sensor de ultrasonidos están activos o no, esta variable permite 
	hacer un apagado o encendido de los láseres en caliente, cosa que no suele ser habitual en
	robótica pero ya que nos encontramos en un entorno de simulación puede ser interesante la 
	posibilidad de apagar estos láseres con el fin de reducir la cantidad de código a ejecutar por
	el robot lo que haría que el rendimiento mejore.
	
	\item \textbf{this.distanceArray}: Se trata de un objeto \emph{JavaScript} que contiene tres
	variables de tipo \emph{Array} en las cuales se guardan las distancias que detectan los sensores
	de ultrasonidos, está dividido en tres grupos; centro, izquierda y derecha lo que permite 
	conocer la ubicación del objeto que se está detectando.
	
	\item \textbf{this.understandedColors}: Es una variable interna del robot que permite mapear 
	(vincular un valor o serie de valores a otro distinto) un color de entrada como tipo \emph{string}
	a sus \emph{arrays} de filtros RGB (Red-Green-Blue) para poder detectarlo mediante el uso de 
	herramientas de OpenCVjs lo que permite hacer una simplificación para detectar objetos mediante su
	color para usuarios que no tengan conocimientos en imagen. Actualmente se implementan las
	componentes primarias y el color blanco.
	
	\item \textbf{this.velocity}: Es una variable de configuración de la velocidad inicial del robot
	en los distintos ejes (por defecto cero en todos ellos). Esta variable es importante ya que 
	a la hora de programar la lógica del robot necesitaremos conocer la velocidad actual, esto nos 
	permite tenerla guardada para su uso tanto por los motores como por los usuarios.
\end{itemize}


Por último el constructor del robot llama a los métodos de arranque de motores, cámara y sensor de 
ultrasonido que se explicarán más detalladamente en sus correspondientes subsecciones.

La figura ~\ref{fig:constructor-robot} muestra el código del constructor del robot, como se ve en la 
imagen la variable \emph{this.understandedColors} es una simplificación de los filtros a aplicar en 
una imagen para detectar un objeto con dicho color.
\begin{figure}[h]
	\centering
	\includegraphics[width=11.5cm, height=11.5cm]{img/robot-constructor.png}
	\caption{Código del constructor del objeto robot, la variable \emph{this} hace referencia al 
	contexto.}
	\label{fig:constructor-robot}
\end{figure}


\subsection{Motores}

En el siguiente apartado se explicará la función de los motores en el robot simulado, cómo se inician
y a qué submétodos llama.\\

La función principal de los motores es la de permitir el movimiento del robot en el plano horizontal a
la velocidad configurada por el usuario. Además un objetivo secundario para esta interfaz es que los
motores funcionen de manera autónoma, es decir, que no tengamos que enviar constantemente una 
instrucción al robot para que este se mueva sino que al configurar la velocidad al robot este se mueva
de manera autónoma.\\

Antes de explicar la funcionalidad completa del motor hay que hacer un inciso en lo que representa las
velocidades configuradas en la variable \emph{this.velocity} en el que tenemos 3 velocidades distintas
en función de cada eje (X-Y-Z). En el eje X tendremos la velocidad en el plano horizontal, la velocidad
lineal, de manera simplificada sería la velocidad a la que se mueve el robot en la dirección en la 
que mira. En el eje Y tendremos la velocidad en la cual se eleva el robot (debido al sistema
de coordenadas tomado en AFRAME donde Y es la altura), esta velocidad no es utilizada en el robot. En
el eje Z tendremos la velocidad de giro. 

Inicialmente se llama desde el constructor del objeto robot y una vez arrancado los pasos que ejecuta
la función son los siguientes:

\begin{itemize}
	\item Obtenemos la rotación, esto se hace debido a que, como me encuentro en un sistema de 
	coordenadas, necesito saber hacia donde mira el robot para poder moverlo hacia adelante y atrás 
	correctamente. 
	
	\item Calculo de la nueva posición, como se ha comentado en el punto anterior, necesito calcular 
	la nueva posición en función de la velocidad lineal configurada en ese instante y en función del 
	vector de vista (hacia donde mira el robot). Para calcular dicha posición es necesaria la rotación,
	la velocidad lineal y la posición actual del robot. Se ha utilizado una descomposición de vectores
	en sus componentes en el eje X-Z para calcular la nueva posición
	\begin{figure}[h]
		\centering
		\includegraphics[width=11cm, height=2.5cm]{img/pos-equation.png}
		\caption{Calculo de la nueva posición en función del ángulo de rotación y la velocidad lineal.}
	\end{figure}
	
	\item Establecemos la nueva posición para el objeto en la escena, se establece la nueva posición
	previamente calculada en la escena. Además se establece la velocidad angular del robot.
	
	\item Se establece un temporizador para que la función se llame así misma, esto se hace para que
	la función se ejecute así misma constantemente y no tener que estar enviando constantemente 
	instrucciones de velocidad lo que simplifica el código.
\end{itemize}


Gracias a esta última instrucción nativa de \emph{JavaScript} podemos crear una función autónoma, por
tanto, el modo de usar los motores se simplifica, el usuario únicamente llama a la función \emph{setV}
que guarda en la variable interna \emph{this.velocity} la velocidad pasada como parámetro a la función
y será la función autónoma del motor la que se encargará de comprobar este registro para saber cuál es 
la velocidad configurada por el usuario. Esto permite simular una hebra dentro del navegador.\\

Otros métodos relacionados con los motores del robot serían:
\begin{itemize}
	\item \textbf{getV}: Método para que el usuario pueda conocer la velocidad lineal actual configurada
	en el robot.
	
	\item \textbf{getW}: Método para que el usuario pueda conocer la velocidad angular actual
	configurada en el robot.
	
	\item \textbf{getL}: Método para que el usuario pueda conocer la velocidad de elevación 
	configurada en el robot.
	
	\item \textbf{setV}: Método para que el usuario configure la velocidad lineal del robot.
	
	\item \textbf{setW}: Método para que el usuario configure la velocidad angular del robot.
	
	\item \textbf{setL}: Método para que el usuario configure la velocidad de elevación del robot.
	
	\item \textbf{move}: Método que combina la funcionalidad de \emph{setV} y \emph{setW}.
	
\end{itemize}

A continuación en la figura ~\ref{fig:motor-esquema} se presenta un esquema de la ejecución de la 
función \emph{setVelocity} del robot.

\begin{figure}[h]
	\centering
	\includegraphics[width=16cm, height=9cm]{img/EJECUCION-MOTOR.png}
	\caption{Esquema de ejecución de la función \emph{setVelocity}, en la parte superior izquierda
	de la imagen se muestran algunos datos que existen en el contexto de la función.}
	\label{fig:motor-esquema}
\end{figure}


\subsection{Sensores}

En este apartado se explicarán cómo se inician los sensores, las funciones de acceso a los datos de
los sensores y cómo funcionan internamente en el objeto robot.\\

Se han implementado dos tipos de sensores, sensores de infrarrojos que permiten detectar una línea 
que se encuentre bajo el robot y el sensor de ultrasonido que permite detectar obstáculos abarcando un 
radio de 180º por delante del frontal del robot.

El sensor de infrarrojos se ha implementado mediante el propio uso de la cámara por simplicidad y 
por mejora de rendimiento, lo que se hace internamente es recortar la imagen de la cámara hasta 
quedarnos con los píxeles que se encuentran más abajo en la imagen, el ancho de la imagen se mantiene,
la imagen recortada tiene unas dimensiones de 5px de alto y 150px de ancho lo que permite que el robot
detecte únicamente lo que tiene inmediatamente debajo. 

La función \emph{readIR} es la encargada de simular este sensor de infrarrojo, toma como parámetro de
entrada un color pero como \emph{string} y accede a la variable anteriormente mencionada 
\emph{understandedColors} para obtener los filtros para el color seleccionados, después recorta la 
imagen para obtener una imagen de 5x150 px. Posteriormente filtra la imagen para obtener únicamente 
la línea a seguir y calcula el centro de la línea mediante las funciones \emph{findContours y moments}
de la librería OpenCVjs.

La salida de la función son valores entre 0 y 3 que representan lo siguiente:
\begin{itemize}
	\item \textbf{0}: Los dos sensores infrarrojos están detectando la línea.
	
	\item \textbf{1}: Únicamente el sensor infrarrojo de la izquierda detecta la línea.
	
	\item \textbf{2}: Únicamente el sensor infrarrojo de la derecha detecta la línea.
	
	\item \textbf{3}: Ninguno de los sensores detecta la línea.
\end{itemize}

Esta simplificación es debida a la implementación existente en el robot real, un objetivo en el futuro
es que el mismo programa creado en el robot se pueda exportar al robot real y funcione de la misma
manera, por tanto ha sido necesaria crear esta adaptación.\\

Como ya se ha comentado en este apartado se ha creado también el sensor de ultrasonido, este sensor 
ha sido simulado mediante el elemento \emph{raycaster} existente en AFRAME que se asemeja a un láser y
nos permite conocer el punto de intersección entre el láser y un determinado objeto.

Para la simulación de este sensor tenemos dos partes:
\begin{itemize}
	\item Componente AFRAME \textbf{followBody}: Este componente tiene una función muy simple, anclar 
	al robot un componente de tipo \emph{raycaster} en este caso sin tener que añadirle físicas, ya que,
	al aplicarle físicas a una entidad se le aplican también a todos sus elementos 'hijo' dentro del
	HTML. Este componente permite que los \emph{raycasters} sigan la posición del robot manteniendo
	su orientación respecto del robot.
	
	\item Componente AFRAME \textbf{intersectionHandler}: Este componente es el más importante ya que
	nos permite manejar correctamente el evento que se dispara cuando hay una intersección para un 
	\emph{raycaster}, los eventos tienen todos el mismo nombre más el número de identificación del 
	\emph{raycaster} que lanza el evento, esto se lleva a cabo para poder detectar que \emph{raycaster}
	lanza el evento y poder guardar correctamente la distancia que detecta.
	
	\item \textbf{startRaycasters}: Función interna del objeto robot que sirve para iniciar los
	\emph{raycasters} dándoles su ángulo de rotación respecto al robot y agrupándolos en función 
	de su posición (izquierda - centro - derecha), les da un identificador numérico que permite
	crear un evento individual para cada uno de ellos y además una vez creados los \emph{raycasters} 
	llama a la función que declara los escuchadores de eventos individuales para cada uno de ellos.
	
	\item \textbf{createRaycasters}: Función que crea un \emph{raycaster} configurando una serie de
	atributos como la distancia a la que se detectarán intersecciones. Además se le añade los
	componentes anteriormente mencionados \emph{followBody} e \emph{intersectionHandler}.
	
	\item \textbf{stopRaycasters}: Función que elimina todos los elementos \emph{raycaster} del robot,
	es decir, para el sensor de ultrasonido.
	
	\item \textbf{setListener}: Declara dos escuchadores de eventos, uno para el evento 
	\emph{intersection-detected-'id del raycaster'} y otro para el evento 
	\emph{intersection-cleared-'id del raycaster'} junto con las funciones a las que llamar cuando
	ocurra cada uno de los dos eventos.
	
	\item \textbf{removeListener}: Función que elimina el escuchador de eventos, es llamada desde la
	función \emph{stopRaycasters}.
	
	\item \textbf{updateDistance}: Función que se llama cuando se detecta el evento 
	\emph{intersection-detected-'id del raycaster'}, esta función actualiza el array de distancias
	 detectadas por los \emph{raycasters}.
	
	\item \textbf{eraseDistance}: Función que se lanza cuando se detecta el evento
	\emph{intersection-cleared-'id del raycaster'}, esta función elimina el registro del array de 
	distancias para el \emph{raycaster} que lanza el evento y elimina dicho registro.
	
	\item \textbf{getDistance y getDistances}: Estas dos funciones son las que se sirven para el 
	usuario final, ambas funciones devuelven las distancias detectadas por los \emph{raycasters}, 
	la diferencia principal es que la primera función únicamente devuelve la distancia que detecta
	el \emph{raycaster} central mientras que la segunda devuelve las distancia para todos ellos.
\end{itemize}

El inicio de los sensores de ultrasonido es simple, el constructor llama a la función 
\emph{startRaycasters} y esta se encarga de configurar todo lo necesario para los sensores de 
ultrasonido.\\


Como resumen, el usuario normalmente usará los métodos \textbf{getDistance, getDistances y readIR} para
obtener los datos de los sensores de ultrasonido e infrarrojo respectivamente.


\subsection{Cámara}

Para la simulación de la cámara del robot se utiliza el componente \emph{spectator} que utiliza
un \emph{renderer} de la librería \emph{three.js} para obtener la imagen de la escena. Posteriormente
en el objeto robot se crean una serie de métodos que permiten configurar y acceder a los datos de la
cámara. A continuación se enumeran los método y se explica su función.

\begin{itemize}

	\item \textbf{startCamera}: Esta función comprueba si la etiqueta con ID 'spectatorDiv' tiene una
	etiqueta 'hijo' que es una etiqueta de tipo \textbf{canvas} donde se representa la cámara. Una vez
	haya cargado la etiqueta se accede al DOM para tomar el contenido de la etiqueta y se llama a la
	función \emph{getImageData-async}.
	
	\item \textbf{getImageData-async}: Función que se ejecuta de manera similar a la función 
	\emph{setVelocity}, toma la imagen de manera autónoma haciendo uso de la función \emph{imread} de la
	librería OpenCVjs y guarda los datos de la imagen en la variable \emph{this.imagedata}. Por último
	se llama a si misma la función pasados 33 milisegundos (30 FPS). Sería una hebra más del simulador.
	
	\item \textbf{getImage}: Esta función la usará el usuario final para obtener los datos de la cámara
	para realizar la lógica que se necesite.
	
\end{itemize}

Además de estos métodos se ofrecen una serie de métodos algo más elaborados, a continuación se 
enumeran y explican:

\begin{itemize}
	\item \textbf{getObjectColor y getObjectColorRGB}: Ambas funciones resuelven el mismo problema pero
	con parámetros de entrada distintos, su función es la de filtrar un objeto que detecta la cámara
	del robot mediante su color. Devuelve un objeto con las coordenadas del centro del objeto en la 
	imagen y el área del objeto en la imagen. La primera función toma como parámetro de entrada 
	el color del objeto a detectar pero como tipo \emph{string}, la segunda función toma como valores
	de entrada los filtros de color que vamos a usar para detectar un elemento en la imagen.
	
\end{itemize}


\newpage
\section{HAL API, \emph{Hardware Abstraction Layer}}
\label{sec:hal-api}

A continuación se muestra una tabla con el API, si no es posible hacer zoom para ver la imagen ir a los
links de los repositorios donde se encuentra la documentación del API en el fichero README.


\begin{longtable}[c]{|p{5cm}|c|}
\hline
\rowcolor[HTML]{00D2CB} 
Método & Descripción \\ \hline
\endhead
%
.setV(velLineal) & \begin{tabular}[c]{@{}c@{}}Mueve hacia delante o atrás el robot.\\ INPUT:\\ - velLineal: numero con la velocidad lineal.\end{tabular} \\ \hline
.setW(velAngular) & \begin{tabular}[c]{@{}c@{}}Hace girar al robot.\\ INPUT:\\ - velAngular: numero con la velocidad angular.\end{tabular} \\ \hline
.setL(velElevacion) & \begin{tabular}[c]{@{}c@{}}Hace que el robot se mueva hacia arriba.\\ INPUT:\\ - velElevacion: numero con la velocidad de elevación\end{tabular} \\ \hline
.move(velLineal, velAngular) & \begin{tabular}[c]{@{}c@{}}Mueve el robot hacia delante/atrás y gira al mismo tiempo.\\ INPUT:\\ Los mismos parámetros que en setV y setW.\end{tabular} \\ \hline
.getV() & \begin{tabular}[c]{@{}c@{}}Obtener la velocidad lineal configurada en el robot.\\ OUTPUT:\\ number\end{tabular} \\ \hline
.getW() & \begin{tabular}[c]{@{}c@{}}Obtener la velocidad angular configurada en el robot.\\ OUTPUT:\\ number\end{tabular} \\ \hline
.getL() & \begin{tabular}[c]{@{}c@{}}Obtener la velocidad de elevación configurada en el robot.\\ OUTPUT:\\ number\end{tabular} \\ \hline
.getImage() & \begin{tabular}[c]{@{}c@{}}Obtener la imagen de la cámara en el robot\\ OUTPUT:\\ cv.Mat() con la imagen de la cámara del robot.\end{tabular} \\ \hline
.getObjectColor(color) & \begin{tabular}[c]{@{}c@{}}Devuelve un objeto con datos sobre el objeto\\  que detecte la cámara con el color pasado \\ como parámetro devuelve un objeto \\ del siguiente tipo \\ INPUT:\\ -color: color como string.\\ OUTPUT:\\ \{center: {[}cx, cy{]}, area: areaInt \}\end{tabular} \\ \hline
.getObjectColorRGB(filtroBajo, filtroAlto) & \begin{tabular}[c]{@{}c@{}}Devuelve un objeto con datos sobre el objeto\\  que detecte la cámara con el color pasado\\  como parámetro devuelve un objeto del siguiente tipo \\ INPUT:\\ - filtroBajo: lista de longitud 4 con valores 0 a 255 (RGBA)\\ - filtroAlto: lista de longitud 4 con valores de 0 a 255 (RGBA)\\ OUTPUT:\\ \\ \{ center: {[}cx, cy{]}, area: areaInt \}\end{tabular} \\ \hline
.getRotation() & \begin{tabular}[c]{@{}c@{}}Devuelve un objeto con la rotación del robot en los 3 ejes\\ OUTPUT:\\ \{\\ x: rotacionX\\ y: rotacionY\\ z: rotacionZ\\ \}\end{tabular} \\ \hline
.followLine(filtroBajo, filtroAlto, velocidadLineal) & \begin{tabular}[c]{@{}c@{}}Simplificación del algoritmo del sigue lineas\\ INPUT:\\ Se utilizan los mismos inputs que para los metodos \\ getObjectColorRGB() y setV()\end{tabular} \\ \hline
.readIR(color) & \begin{tabular}[c]{@{}c@{}}Permite obtener valores entre 0-3 que simulan \\ el uso de sensores infrarrojos para un \\ color de linea pasado como parámetro\\ INPUT:\\ -color: color a filtrar en la imagen como string\end{tabular} \\ \hline
.getDistance() & \begin{tabular}[c]{@{}c@{}}Permite obtener la distancia del objeto que tiene delante\\ OUTPUT:\\ number\end{tabular} \\ \hline
.getDistances() & \begin{tabular}[c]{@{}c@{}}Permite obtener la distancia de los objetos detectados\\  en un arco de 180º, devuelve 31 valores por defecto\\ OUTPUT\\ Lista con 31 valores de tipo number.\end{tabular} \\ \hline
.getPosition() & \begin{tabular}[c]{@{}c@{}}Permite obtener la posición del robot en la escena\\ OUTPUT:\\ \{ \\ x: coordenadax\\ y: coordenaday\\ z: coordenadaz\\ theta: rotacion eje Y (horiz)\\ \}\end{tabular} \\ \hline
\end{longtable}


\newpage
\section{Empaquetado}
\label{sec:empaquetado}

En esta sección se explicará el empaquetado final de \emph{WebSim} y . Para empaquetarlo se ha hecho 
uso de los \emph{import} de ES6 y la herramienta \emph{WebPack} que permite generar un único fichero 
con todas las dependencias de un aplicación y, en modo producción, permite también minificar (reducir) 
el código de la aplicación una vez empaquetado.\\

Lo primero que ha sido necesario es instalar las dependencias a través de la herramienta NPM, lo que
hace que pueda importar posteriormente desde el punto principal de lo que será mi empaquetado dicha
dependencia. Lo que se ha hecho es desde el archivo \textbf{websim.js} importar las dependencias de
\emph{AFRAME, AFRAME-PHYSICS y jQuery} además de exportar desde otros archivos las clases y funciones
necesarias en el archivo principal.\\

La aplicación se empaquetará con WebPack y gracias a esta combinación tendremos un único \emph{bundle}
en el cual se incluirán todas las dependencias. A continuación se muestra en la figura 
~\ref{fig:webpack} el fichero de configuración de \emph{WebPack} para empaquetar WebSim.

\begin{figure}
	\centering
	\includegraphics[width=6cm, height=10cm]{img/webpack.png}
	\caption{Fichero de configuración de la herramienta WebPack.}
	\label{fig:webpack}
\end{figure}

En la figura ~\ref{fig:webpack} se muestra cuál es fichero de entrada en el que WebPack buscará los
\emph{imports} y el fichero de salida de todas las dependencias empaquetadas. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% USO DEL SIMULADOR %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Usos del simulador}
\label{chap:usos}

Como se ha comentado en el apartado de objetivos del presente documento, los usos del simulador serán
educativos. Se ha enfocado la aplicación de manera que los usuarios aprenderán a programar la lógica
del robot usando una simplificación de acceso a los sensores y actuadores del robot simulado.

Se ha preparado la aplicación para desarrollar una serie de ejercicios ya establecidos previamente al
proyecto. En la siguiente sección se explicarán los distintos ejercicios.

\newpage
\section{Programando con \emph{JavaScript}}
\label{sec:ejercicios-js}

Como se ha comentado en el inicio del capítulo existen 3 ejercicios predefinidos que utiliza la 
plataforma \textbf{JdeRobot Kids} para enseñar a los alumnos programación de robots y visión artificial.
Como lo que tenemos es una aplicación con un editor de código \emph{JavaScript} se pueden incluso crear
otro tipo de ejercicios ampliando el espectro de aprendizaje para los alumnos como por ejemplo conseguir
mover el robot mediante teclado lo que les lleva a conocer la orientación a eventos de \emph{JavaScript}
y el manejo de estos, en concreto los eventos del teclado.\\

Una muestra de este ejercicio se enseña en el siguiente enlace (mover el robot con el teclado):

\url{https://www.youtube.com/watch?v=LlGeu95gEtk&t=1s}\\


A continuación se muestra una lista de enlaces a los ejercicios propuestos por \textbf{JdeRobot Kids}
resueltos:
\begin{itemize}
	\item Seguir un objeto detectado por su color:\\
	\url{https://www.youtube.com/watch?v=9JIZO5E3jUo}
	
	\item Ejercicio sigue líneas:\\
	\url{https://www.youtube.com/watch?v=tzxxEyA-LWs}
	
	\item Ejercicio evitar obstáculos:\\
	\url{https://www.youtube.com/watch?v=VDW9FZcwA0g&t=8s}
\end{itemize}


Estos ejercicios lo único que tienen de diferente es el escenario de \emph{AFRAME} (página HTML) por lo
que se pueden crear distintas paginas para plantear tantos ejercicios como se quiera con el mismo robot.



\newpage
\section{Programando con \emph{Blockly}}
\label{sec:ejercicios-blockly}

Haciendo uso del mismo core de \emph{WebSim} se ha creado una pequeña aplicación para la resolución de
los ejercicios planteados en \textbf{JdeRobot Kids} mediante el uso de bloques visuales con 
\emph{Blockly}.\\

Esta aplicación se ha creado para una toma de contacto con la lógica de programación de robots para 
usuarios no introducidos en el lenguaje \emph{JavaScript}. En la figura ~\ref{fig:interfaz-blockly}
se muestra la interfaz de bloques visuales en la que se ve que no es necesario programar, es una 
interfaz de tipo \textbf{Plug and Play} en la que se conectan los bloques unos con otros para
generar código.

\begin{figure}[h]
	\centering
	\includegraphics[width=16cm, height=9cm]{img/interfaz-blockly.png}
	\caption{Interfaz de la aplicación WebSim + Blockly}
	\label{fig:interfaz-blockly}
\end{figure}

A continuación se muestran enlaces a vídeos que muestran los ejercicios resueltos:
\begin{itemize}
	\item Seguir un objeto detectado por su color:\\
	\url{https://www.youtube.com/watch?v=GOaxPyp0Lk4}
	
	\item Ejercicio sigue líneas:\\
	\url{https://www.youtube.com/watch?v=iouvTDALMl8}
	
	\item Ejercicio evitar obstáculos:\\
	\url{https://www.youtube.com/watch?v=yKXP3UIAxtg}
\end{itemize}

Como se ve los bloques son autodescriptivos, cada bloque indica su propia funcionalidad.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones}
\label{chap:conclusiones}


\section{Valoración objetivo final}
\label{sec:valoracion_objetivo_final}

Al repasar los objetivos del capítulo ~\ref{chap:objetivos} concluimos que se ha conseguido llevar a 
cabo los puntos establecidos ya que el principal punto era crear un simulador en lado cliente. Como
se ha podido intuir a lo largo del documento no existe un servidor con una gran funcionalidad, al 
contrario, el servidor utilizado es un servidor estático que ofrece la plataforma de \textbf{Github}.\\

Además como se comentó al inicio, este simulador es la base funcional, hay muchas características 
interesantes que se podrán ir implementando a posteriori como podría ser el soporte de distintos 
prototipos de robots como por ejemplo drones y habrá que seguir en detalle también las nuevas
características que se irán añadiendo en el entorno \emph{AFRAME} que permitirán mejorar el rendimiento
y funcionalidad de la plataforma.


\newpage
\section{Aplicación de lo aprendido}
\label{sec:aplicacion_aprendido}

Para llevar acabo el proyecto me han sido imprescindibles los conocimientos adquiridos en las 
asignaturas relacionadas con la programación y tratamiento de imagen, a continuación se enumeran
las asignaturas relacionadas con estos campos cursadas en el Grado.

\begin{itemize}
	\item Informática I con el lenguaje 'Picky' en el cual tuve una primera toma de contacto con los
	fundamentos de programación.
	
	\item Informática II, avance de Informática I en el cual se llevaron a cabo proyectos algo más
	elaborados y se profundizó en el aprendizaje de 'punteros'.
	
	\item Protocolos de Transmisión de Audio y Vídeo en Internet, esta asignatura fue la primera 
	aproximación con un lenguaje de programación orientado a objetos como \emph{Python}.
	
	\item Graficos y visualización 3D, esta asignatura ha sido una de las claves de aprendizaje para el
	desarrollo del proyecto ya que fue mi primera toma de contacto con el lenguaje \emph{JavaScript} y 
	el \textbf{canvas}.
	
	\item Laboratorios en Tecnologías y Aplicaciones Web, el segundo punto clave de aprendizaje ya que
	estableció la base de conocimiento sobre tecnologías web como NodeJS y Django.
	
	\item Tratamiento digital de la imagen, esta asignatura ha sido importante debido a que ha 
	establecido la base de conocimiento sobre filtrado de imagen necesario para su uso con el robot.
\end{itemize}


Durante el proyecto he aprendido muchísimo sobre tecnologías web como el uso de herramientas de 
empaquetado como Webpack, he mejorado mucho en el uso de control de versiones en la plataforma Github.
Además he aprendido cómo estructurar una aplicación completa mediante el uso de módulos de código 
separados. Por último he aprendido cómo usar los paquetes \emph{NPM} como dependencias de código
lo que simplifica mucho la utilización de la aplicación e instalación de dependencias.


\newpage
\section{Mejoras futuras}
\label{sec:mejoras_futuras}

Como futuras mejoras hay muchas por abarcar, a continuación se enumeran algunas de ellas:

\begin{itemize}
	\item Permitir que \emph{WebSim} utilice un fichero de configuración para crear el robot.
	\item Añadir funcionalidad de guardado de código en el servidor para los alumnos.
	\item Extender el soporte para otros robots con distinta funcionalidad.
	\item Mejora general de la escena de AFRAME.
	\item Integrar con el robot real, esto se hará en un futuro inmediato.
	\item Explorar mejoras de rendimiento.
	\item Explorar portabilidad a otros navegadores como Chrome, Safari, etc. Aunque algunos de ellos
	no soportan el entorno AFRAME.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\appendix
\chapter{Manual de usuario}
\label{app:manual}

Para el uso del proyecto podemos instalarlo en local que se explicará a continuación o bien se puede
acceder a la siguiente URL. Es necesario acceder con el navegador \textbf{Firefox}.\\

\url{https://jderobot.github.io/WebSim/}\\
\url{https://roboticsurjc-students.github.io/2018-tfg-alvaro_paniagua/}

\section{Instalación}
\label{sec:instalacion}

Para la instalación en local necesitamos tener instalados NodeJS y NPM, para ello tenemos que abrir
una consola (Ubuntu/Linux) o un CMD (Windows)

\begin{itemize}
	\item Ubuntu/Linux:
	\begin{lstlisting}[language=bash]
  		$ sudo apt update
  		$ sudo apt get install nodejs
  		$ sudo apt get install npm
  		
  		-- Para comprobar que Node está instalado:
  		
  		$ nodejs --version
	\end{lstlisting}
	
	\item Windows: Descarga el instalador de NodeJS de su página oficial.
\end{itemize}

Una vez instalado, copia el repositorio que quieras utilizar de los que se muestran a continuación:

\url{https://github.com/RoboticsURJC-students/2018-tfg-alvaro_paniagua}\\
\url{https://github.com/JdeRobot/WebSim}\\

Muévete a la carpeta del repositorio que acabes de clonar y pon lo siguiente:

\begin{lstlisting}[language=bash]
$ npm install
\end{lstlisting}

Esto instalará todas las dependencias en la carpeta 'node-modules', una vez finalizado esto podremos
arrancar el servidor, para ello tenemos dos opciones.

\begin{itemize}
	\item Python: Necesitamos tener instalado python en nuestro equipo, si lo tenemos instalado
	ejecutamos la siguiente instrucción en la línea de comandos:
	\begin{lstlisting}[language=bash]
	-- Python v.3
	$ python -m http.server [port]
	-- Python v.2
	$ python -m SimpleHTTPServer [port]
	\end{lstlisting}
	
\end{itemize}


\chapter{Enlaces a tutoriales de uso}
\label{app:tutoriales}

En el siguiente enlace se muestra el canal de Youtube de la plataforma \emph{JdeRobot} en el que,
filtrando por 'websim', se podrán encontrar vídeotutoriales de uso del simulador.\\

\url{https://www.youtube.com/channel/UCgmUgpircYAv_QhLQziHJOQ?view_as=subscriber}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

% Las siguientes dos instrucciones es todo lo que necesitas
% para incluir las citas en la memoria
\bibliographystyle{abbrv}
\bibliography{memoria}  % memoria.bib es el nombre del fichero que contiene
% las referencias bibliográficas. Abre ese fichero y mira el formato que tiene,
% que se conoce como BibTeX. Hay muchos sitios que exportan referencias en
% formato BibTeX. Prueba a buscar en http://scholar.google.com por referencias
% y verás que lo puedes hacer de manera sencilla.
% Más información:
% http://texblog.org/2014/04/22/using-google-scholar-to-download-bibtex-citations/

Google Blockly:

\url{https://developers.google.com/speed/docs/insights/MinifyResources?hl=es-419}

Historia JavaScript:

\url{https://medium.com/@benastontweet/lesson-1a-the-history-of-javascript-8c1ce3bffb17}

Documentación Webpack:

\url{https://webpack.js.org/}

Vídeo de Youtube para configurar Webpack:

\url{https://www.youtube.com/watch?v=PakrjWSD6Mo}

Documentación HTML:

\url{https://www.computerhope.com/jargon/h/html.htm}

Configuración Webpack:

\url{https://jgbarah.github.io/aframe-playground/figures-02/}

NPM para principiantes:

\url{https://www.impressivewebs.com/npm-for-beginners-a-guide-for-front-end-developers/}

Documentación completa AFRAME:

\url{https://aframe.io/}

Documentación jQuery:

\url{https://jquery.com/}
\end{document}
